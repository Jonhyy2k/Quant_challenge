{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71c9809f-f5cc-45ee-86b6-d66a21799215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.4 | packaged by Anaconda, Inc. | (main, Jun 18 2024, 15:03:56) [MSC v.1929 64 bit (AMD64)]\n",
      "Arch: AMD64 | OS: Windows\n"
     ]
    }
   ],
   "source": [
    "import sys, platform\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Arch:\", platform.machine(), \"| OS:\", platform.system())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b550998-4440-4926-9e48-414bb0c1c6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: blpapi in c:\\users\\antoniovd\\.conda\\envs\\bbg310\\lib\\site-packages (3.25.7.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install blpapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62bed2e6-4b8f-4742-979f-dd9b5636d845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.2-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.2.6-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.15.3-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.6-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\antoniovd\\.conda\\envs\\bbg310\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp310-cp310-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.60.0-cp310-cp310-win_amd64.whl.metadata (113 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp310-cp310-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\antoniovd\\.conda\\envs\\bbg310\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.3.0-cp310-cp310-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.4-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\antoniovd\\.conda\\envs\\bbg310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.2-cp310-cp310-win_amd64.whl (11.3 MB)\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 11.3/11.3 MB 54.3 MB/s  0:00:00\n",
      "Downloading numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 8.4/12.9 MB 65.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 30.0 MB/s  0:00:00\n",
      "Downloading scipy-1.15.3-cp310-cp310-win_amd64.whl (41.3 MB)\n",
      "   ---------------------------------------- 0.0/41.3 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 3.4/41.3 MB 16.7 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 5.0/41.3 MB 12.1 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 8.7/41.3 MB 13.4 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 10.0/41.3 MB 11.9 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 11.8/41.3 MB 11.2 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 14.7/41.3 MB 11.5 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 17.0/41.3 MB 11.3 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 19.1/41.3 MB 11.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 20.4/41.3 MB 10.6 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 23.1/41.3 MB 10.8 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 24.6/41.3 MB 10.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 26.7/41.3 MB 10.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 29.9/41.3 MB 10.7 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 32.8/41.3 MB 10.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 35.4/41.3 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 37.7/41.3 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.6/41.3 MB 11.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  41.2/41.3 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.3/41.3 MB 10.1 MB/s  0:00:04\n",
      "Downloading matplotlib-3.10.6-cp310-cp310-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 2.9/8.1 MB 14.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.0/8.1 MB 13.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.9/8.1 MB 12.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 11.4 MB/s  0:00:00\n",
      "Downloading contourpy-1.3.2-cp310-cp310-win_amd64.whl (221 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.60.0-cp310-cp310-win_amd64.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ------------------------------------ --- 2.1/2.3 MB 29.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 9.9 MB/s  0:00:00\n",
      "Downloading kiwisolver-1.4.9-cp310-cp310-win_amd64.whl (73 kB)\n",
      "Downloading pillow-11.3.0-cp310-cp310-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 7.0/7.0 MB 43.1 MB/s  0:00:00\n",
      "Downloading pyparsing-3.2.4-py3-none-any.whl (113 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pyparsing, pillow, numpy, kiwisolver, fonttools, cycler, scipy, pandas, contourpy, matplotlib\n",
      "\n",
      "   ----------------------------------------  0/12 [pytz]\n",
      "   ----------------------------------------  0/12 [pytz]\n",
      "   ----------------------------------------  0/12 [pytz]\n",
      "   ----------------------------------------  0/12 [pytz]\n",
      "   ----------------------------------------  0/12 [pytz]\n",
      "   ----------------------------------------  0/12 [pytz]\n",
      "   ----------------------------------------  0/12 [pytz]\n",
      "   ----------------------------------------  0/12 [pytz]\n",
      "   ----------------------------------------  0/12 [pytz]\n",
      "   ----------------------------------------  0/12 [pytz]\n",
      "   --- ------------------------------------  1/12 [tzdata]\n",
      "   --- ------------------------------------  1/12 [tzdata]\n",
      "   --- ------------------------------------  1/12 [tzdata]\n",
      "   --- ------------------------------------  1/12 [tzdata]\n",
      "   --- ------------------------------------  1/12 [tzdata]\n",
      "   --- ------------------------------------  1/12 [tzdata]\n",
      "   --- ------------------------------------  1/12 [tzdata]\n",
      "   --- ------------------------------------  1/12 [tzdata]\n",
      "   --- ------------------------------------  1/12 [tzdata]\n",
      "   --- ------------------------------------  1/12 [tzdata]\n",
      "   --- ------------------------------------  1/12 [tzdata]\n",
      "   --- ------------------------------------  1/12 [tzdata]\n",
      "   ------ ---------------------------------  2/12 [pyparsing]\n",
      "   ------ ---------------------------------  2/12 [pyparsing]\n",
      "   ---------- -----------------------------  3/12 [pillow]\n",
      "   ---------- -----------------------------  3/12 [pillow]\n",
      "   ---------- -----------------------------  3/12 [pillow]\n",
      "   ---------- -----------------------------  3/12 [pillow]\n",
      "   ---------- -----------------------------  3/12 [pillow]\n",
      "   ---------- -----------------------------  3/12 [pillow]\n",
      "   ---------- -----------------------------  3/12 [pillow]\n",
      "   ---------- -----------------------------  3/12 [pillow]\n",
      "   ---------- -----------------------------  3/12 [pillow]\n",
      "   ---------- -----------------------------  3/12 [pillow]\n",
      "   ---------- -----------------------------  3/12 [pillow]\n",
      "   ---------- -----------------------------  3/12 [pillow]\n",
      "   ---------- -----------------------------  3/12 [pillow]\n",
      "   ---------- -----------------------------  3/12 [pillow]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [numpy]\n",
      "   -------------------- -------------------  6/12 [fonttools]\n",
      "   -------------------- -------------------  6/12 [fonttools]\n",
      "   -------------------- -------------------  6/12 [fonttools]\n",
      "   -------------------- -------------------  6/12 [fonttools]\n",
      "   -------------------- -------------------  6/12 [fonttools]\n",
      "   -------------------- -------------------  6/12 [fonttools]\n",
      "   -------------------- -------------------  6/12 [fonttools]\n",
      "   -------------------- -------------------  6/12 [fonttools]\n",
      "   -------------------- -------------------  6/12 [fonttools]\n",
      "   -------------------- -------------------  6/12 [fonttools]\n",
      "   -------------------- -------------------  6/12 [fonttools]\n",
      "   -------------------- -------------------  6/12 [fonttools]\n",
      "   -------------------- -------------------  6/12 [fonttools]\n",
      "   -------------------- -------------------  6/12 [fonttools]\n",
      "   -------------------- -------------------  6/12 [fonttools]\n",
      "   -------------------- -------------------  6/12 [fonttools]\n",
      "   -------------------- -------------------  6/12 [fonttools]\n",
      "   -------------------- -------------------  6/12 [fonttools]\n",
      "   -------------------- -------------------  6/12 [fonttools]\n",
      "   -------------------- -------------------  6/12 [fonttools]\n",
      "   -------------------- -------------------  6/12 [fonttools]\n",
      "   -------------------- -------------------  6/12 [fonttools]\n",
      "   -------------------- -------------------  6/12 [fonttools]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   -------------------------- -------------  8/12 [scipy]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   --------------------------------- ------ 10/12 [contourpy]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ---------------------------------------- 12/12 [matplotlib]\n",
      "\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.60.0 kiwisolver-1.4.9 matplotlib-3.10.6 numpy-2.2.6 pandas-2.3.2 pillow-11.3.0 pyparsing-3.2.4 pytz-2025.2 scipy-1.15.3 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts f2py.exe and numpy-config.exe are installed in 'C:\\Users\\antoniovd\\.conda\\envs\\bbg310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts fonttools.exe, pyftmerge.exe, pyftsubset.exe and ttx.exe are installed in 'C:\\Users\\antoniovd\\.conda\\envs\\bbg310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy scipy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ad9c6ad-4795-473e-8379-17e2aaf11dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Bloomberg Options + Stock Data Loader (fully functional with blpapi) ---\n",
    "# Requirements: Bloomberg Terminal running on this machine (Desktop API) and `pip install blpapi`\n",
    "# Optional: pip install pandas numpy scipy\n",
    "\n",
    "import blpapi\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# ------------------------\n",
    "# Session helpers\n",
    "# ------------------------\n",
    "def _start_bbg_session(host=\"localhost\", port=8194):\n",
    "    \"\"\"Start a Bloomberg API session (desktop API defaults).\"\"\"\n",
    "    session_options = blpapi.SessionOptions()\n",
    "    session_options.setServerHost(host)\n",
    "    session_options.setServerPort(port)\n",
    "\n",
    "    session = blpapi.Session(session_options)\n",
    "    if not session.start():\n",
    "        raise RuntimeError(\"Failed to start Bloomberg session.\")\n",
    "    if not session.openService(\"//blp/refdata\"):\n",
    "        raise RuntimeError(\"Failed to open //blp/refdata.\")\n",
    "    return session, session.getService(\"//blp/refdata\")\n",
    "\n",
    "def _send_request_sync(session, request, timeout_ms=120_000):\n",
    "    \"\"\"Send a request and synchronously collect all response messages.\"\"\"\n",
    "    session.sendRequest(request)\n",
    "    out_msgs = []\n",
    "    while True:\n",
    "        ev = session.nextEvent(timeout_ms)\n",
    "        for msg in ev:\n",
    "            out_msgs.append(msg)\n",
    "        if ev.eventType() == blpapi.Event.RESPONSE:\n",
    "            break\n",
    "    return out_msgs\n",
    "\n",
    "# ------------------------\n",
    "# Stock (BDH â€“ HistoricalDataRequest)\n",
    "# ------------------------\n",
    "def get_equity_history(symbol_bbg: str,\n",
    "                       start_date: str,\n",
    "                       end_date: str,\n",
    "                       fields=(\"PX_LAST\",),\n",
    "                       periodicity=\"DAILY\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Pull historical data for an equity.\n",
    "    symbol_bbg: e.g., 'AAPL US Equity'\n",
    "    dates as 'YYYYMMDD'\n",
    "    \"\"\"\n",
    "    session, ref = _start_bbg_session()\n",
    "    try:\n",
    "        req = ref.createRequest(\"HistoricalDataRequest\")\n",
    "        req.getElement(\"securities\").appendValue(symbol_bbg)\n",
    "        for f in fields:\n",
    "            req.getElement(\"fields\").appendValue(f)\n",
    "        req.set(\"startDate\", start_date)\n",
    "        req.set(\"endDate\", end_date)\n",
    "        req.set(\"periodicitySelection\", periodicity)\n",
    "\n",
    "        msgs = _send_request_sync(session, req)\n",
    "\n",
    "        rows = []\n",
    "        for msg in msgs:\n",
    "            if not msg.hasElement(\"securityData\"): \n",
    "                continue\n",
    "            sd = msg.getElement(\"securityData\")\n",
    "            fd = sd.getElement(\"fieldData\")\n",
    "            for i in range(fd.numValues()):\n",
    "                row = fd.getValueAsElement(i)\n",
    "                d = row.getElementAsDatetime(\"date\")\n",
    "                out = {\"date\": pd.to_datetime(d.strftime(\"%Y-%m-%d\"))}\n",
    "                for f in fields:\n",
    "                    if row.hasElement(f):\n",
    "                        # numbers might be NaN; handle gracefully\n",
    "                        try:\n",
    "                            out[f] = row.getElementAsFloat64(f)\n",
    "                        except Exception:\n",
    "                            out[f] = np.nan\n",
    "                rows.append(out)\n",
    "\n",
    "        df = pd.DataFrame(rows).sort_values(\"date\").set_index(\"date\")\n",
    "        return df\n",
    "    finally:\n",
    "        session.stop()\n",
    "\n",
    "# ------------------------\n",
    "# Options chain tickers (BDS â€“ bulk field CHAIN_TICKERS)\n",
    "# Then detail for each option (BDP â€“ ReferenceDataRequest)\n",
    "# ------------------------\n",
    "def get_option_chain(symbol_bbg: str,\n",
    "                     expiry: str | None = None,\n",
    "                     moneyness: str | None = None,\n",
    "                     put_call: str | None = None,\n",
    "                     max_points: int | None = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retrieve an option chain and key fields for each option using Bloomberg API.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    symbol_bbg : str\n",
    "        Underlying, e.g. 'AAPL US Equity' or 'SPX Index'\n",
    "    expiry : str | None\n",
    "        Override expiry to a specific date, format 'YYYYMMDD' (e.g., '20251219').\n",
    "        (Override field: CHAIN_EXP_DT_OVRD)\n",
    "    moneyness : str | None\n",
    "        Moneyness band like '90%-110%' around spot (Override: CHAIN_STRIKE_PX_OVRD).\n",
    "        You can also pass absolute strikes like '100,105,110'.\n",
    "    put_call : str | None\n",
    "        'C' for calls, 'P' for puts (Override: CHAIN_PUT_CALL_TYPE_OVRD).\n",
    "        Leave None for both.\n",
    "    max_points : int | None\n",
    "        Limit number of chain points returned (Override: CHAIN_POINTS_LIMIT)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame with columns:\n",
    "        - security\n",
    "        - OPT_STRIKE_PX, OPT_EXPIRE_DT, OPT_PUT_CALL\n",
    "        - PX_BID, PX_ASK, MID, IMPLIED_VOLATILITY, DELTA, GAMMA, THETA, VEGA\n",
    "        - OPT_UNDL_PX (underlying), TICKER / UNIQUE_ID if available\n",
    "    \"\"\"\n",
    "    session, ref = _start_bbg_session()\n",
    "    try:\n",
    "        # 1) BDS bulk request for chain tickers\n",
    "        bds_req = ref.createRequest(\"ReferenceDataRequest\")\n",
    "        bds_req.getElement(\"securities\").appendValue(symbol_bbg)\n",
    "        bds_req.getElement(\"fields\").appendValue(\"CHAIN_TICKERS\")  # bulk field\n",
    "\n",
    "        # Overrides (see FLDS <GO> on CHAIN_TICKERS for choices)\n",
    "        overrides = bds_req.getElement(\"overrides\")\n",
    "        if expiry:\n",
    "            ov = overrides.appendElement()\n",
    "            ov.setElement(\"fieldId\", \"CHAIN_EXP_DT_OVRD\")\n",
    "            ov.setElement(\"value\", expiry)\n",
    "        if moneyness:\n",
    "            ov = overrides.appendElement()\n",
    "            ov.setElement(\"fieldId\", \"CHAIN_STRIKE_PX_OVRD\")\n",
    "            ov.setElement(\"value\", moneyness)\n",
    "        if put_call in {\"C\", \"P\"}:\n",
    "            ov = overrides.appendElement()\n",
    "            ov.setElement(\"fieldId\", \"CHAIN_PUT_CALL_TYPE_OVRD\")\n",
    "            ov.setElement(\"value\", put_call)\n",
    "        if max_points:\n",
    "            ov = overrides.appendElement()\n",
    "            ov.setElement(\"fieldId\", \"CHAIN_POINTS_LIMIT\")\n",
    "            ov.setElement(\"value\", str(max_points))\n",
    "\n",
    "        msgs = _send_request_sync(session, bds_req)\n",
    "\n",
    "        # Parse bulk field CHAIN_TICKERS\n",
    "        option_securities = []\n",
    "        for msg in msgs:\n",
    "            if not msg.hasElement(\"securityData\"):\n",
    "                continue\n",
    "            sdata_array = msg.getElement(\"securityData\")\n",
    "            for i in range(sdata_array.numValues()):\n",
    "                sdata = sdata_array.getValueAsElement(i)\n",
    "                if not sdata.hasElement(\"fieldData\"):\n",
    "                    continue\n",
    "                fdata = sdata.getElement(\"fieldData\")\n",
    "                if fdata.hasElement(\"CHAIN_TICKERS\"):\n",
    "                    bulk = fdata.getElement(\"CHAIN_TICKERS\")\n",
    "                    for j in range(bulk.numValues()):\n",
    "                        row = bulk.getValueAsElement(j)\n",
    "                        # rows typically contain a 'Ticker' element\n",
    "                        if row.hasElement(\"Ticker\"):\n",
    "                            option_securities.append(row.getElementAsString(\"Ticker\"))\n",
    "\n",
    "        if not option_securities:\n",
    "            return pd.DataFrame(columns=[\"security\"])\n",
    "\n",
    "        # 2) BDP reference request for each option ticker (bid/ask/iv/greeks/etc.)\n",
    "        fields = [\n",
    "            \"PX_BID\", \"PX_ASK\",\n",
    "            \"IMPLIED_VOLATILITY\",\n",
    "            \"DELTA\", \"GAMMA\", \"THETA\", \"VEGA\",\n",
    "            \"OPT_STRIKE_PX\", \"OPT_EXPIRE_DT\", \"OPT_PUT_CALL\",\n",
    "            \"OPT_UNDL_PX\"\n",
    "        ]\n",
    "        bdp_req = ref.createRequest(\"ReferenceDataRequest\")\n",
    "        secs_el = bdp_req.getElement(\"securities\")\n",
    "        for sec in option_securities:\n",
    "            secs_el.appendValue(sec)\n",
    "        flds_el = bdp_req.getElement(\"fields\")\n",
    "        for f in fields:\n",
    "            flds_el.appendValue(f)\n",
    "\n",
    "        msgs2 = _send_request_sync(session, bdp_req)\n",
    "\n",
    "        # Parse into DataFrame\n",
    "        out = []\n",
    "        for msg in msgs2:\n",
    "            if not msg.hasElement(\"securityData\"):\n",
    "                continue\n",
    "            sdata_array = msg.getElement(\"securityData\")\n",
    "            for i in range(sdata_array.numValues()):\n",
    "                sdata = sdata_array.getValueAsElement(i)\n",
    "                sec = sdata.getElementAsString(\"security\")\n",
    "                fdata = sdata.getElement(\"fieldData\")\n",
    "                row = {\"security\": sec}\n",
    "                for f in fields:\n",
    "                    if fdata.hasElement(f):\n",
    "                        try:\n",
    "                            row[f] = fdata.getElementAsFloat64(f)\n",
    "                        except Exception:\n",
    "                            try:\n",
    "                                # some fields are strings/dates\n",
    "                                row[f] = fdata.getElementAsString(f)\n",
    "                            except Exception:\n",
    "                                row[f] = np.nan\n",
    "                # nice to have: mid\n",
    "                bid = row.get(\"PX_BID\", np.nan)\n",
    "                ask = row.get(\"PX_ASK\", np.nan)\n",
    "                row[\"MID\"] = np.nan if (pd.isna(bid) or pd.isna(ask)) else (bid + ask) / 2.0\n",
    "                out.append(row)\n",
    "\n",
    "        df = pd.DataFrame(out)\n",
    "        # standardize types\n",
    "        if \"OPT_EXPIRE_DT\" in df.columns:\n",
    "            df[\"OPT_EXPIRE_DT\"] = pd.to_datetime(df[\"OPT_EXPIRE_DT\"], errors=\"coerce\")\n",
    "        if \"OPT_PUT_CALL\" in df.columns:\n",
    "            df[\"OPT_PUT_CALL\"] = df[\"OPT_PUT_CALL\"].astype(str).str.upper()\n",
    "        if \"OPT_STRIKE_PX\" in df.columns:\n",
    "            df[\"OPT_STRIKE_PX\"] = pd.to_numeric(df[\"OPT_STRIKE_PX\"], errors=\"coerce\")\n",
    "        return df.sort_values([\"OPT_EXPIRE_DT\", \"OPT_STRIKE_PX\", \"OPT_PUT_CALL\", \"security\"]).reset_index(drop=True)\n",
    "    finally:\n",
    "        session.stop()\n",
    "\n",
    "# ------------------------\n",
    "# Blackâ€“Scholes (for your mispricing logic)\n",
    "# ------------------------\n",
    "def black_scholes(S, K, T, r, sigma, option_type=\"call\"):\n",
    "    d1 = (np.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))\n",
    "    d2 = d1 - sigma * np.sqrt(T)\n",
    "    if option_type.lower() == \"call\":\n",
    "        return S * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)\n",
    "    else:\n",
    "        return K * np.exp(-r * T) * norm.cdf(-d2) - S * norm.cdf(-d1)\n",
    "\n",
    "# ------------------------\n",
    "# Example usage (uncomment to run on a terminal PC)\n",
    "# ------------------------\n",
    "# underlying = \"AAPL US Equity\"\n",
    "# end = datetime.today()\n",
    "# start = end - timedelta(days=120)\n",
    "# hist = get_equity_history(underlying, start.strftime(\"%Y%m%d\"), end.strftime(\"%Y%m%d\"),\n",
    "#                           fields=(\"PX_LAST\",))\n",
    "# chain = get_option_chain(\n",
    "#     underlying,\n",
    "#     expiry=None,             # e.g., '20251219' to target a specific expiry\n",
    "#     moneyness=\"90%-110%\",    # or '100,105,110' for absolute strikes\n",
    "#     put_call=None,           # 'C' for calls only, 'P' for puts only, None for both\n",
    "#     max_points=500           # optional cap\n",
    "# )\n",
    "# print(hist.tail())\n",
    "# print(chain.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13932c99-5135-4c8d-b912-04a07cf7815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== Add a publication-ready plot to the Bloomberg backtest =====================\n",
    "# Requirements:\n",
    "#   - matplotlib (pip install matplotlib)\n",
    "#   - Works with the res dict returned by backtest_parity(...) defined earlier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "def plot_backtest(res, title=\"Parity Arbitrage Backtest\", outfile=None):\n",
    "    \"\"\"\n",
    "    Create a clean equity curve plot from the backtest results and save to PNG.\n",
    "    - res: dict returned by backtest_parity(...)\n",
    "    - title: chart title\n",
    "    - outfile: path to save PNG; if None, saves to ./backtest_<timestamp>.png\n",
    "\n",
    "    The curve is daily **cumulative realized PnL** (units), so itâ€™s ready for reporting.\n",
    "    \"\"\"\n",
    "    # Build a daily cumulative realized PnL series from trade exits\n",
    "    uh = res[\"underlying_history\"].copy()\n",
    "    tr = res[\"trades\"].copy() if not res[\"trades\"].empty else pd.DataFrame(columns=[\"exit_date\",\"pnl\"])\n",
    "\n",
    "    # daily index over backtest window\n",
    "    daily = pd.Series(0.0, index=uh.index)\n",
    "\n",
    "    # add realized PnL on exit dates\n",
    "    if not tr.empty:\n",
    "        tr = tr.set_index(\"exit_date\").sort_index()\n",
    "        for dt, row in tr.iterrows():\n",
    "            if dt in daily.index:\n",
    "                daily.loc[dt] += float(row[\"pnl\"])\n",
    "\n",
    "    cum_pnl = daily.cumsum()  # cumulative realized pnl (units)\n",
    "\n",
    "    # set output file\n",
    "    if outfile is None:\n",
    "        stamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        outfile = Path(f\"./backtest_{stamp}.png\")\n",
    "    else:\n",
    "        outfile = Path(outfile)\n",
    "\n",
    "    # ---- Plot (single figure, no custom colors/styles) ----\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(cum_pnl.index, cum_pnl.values, linewidth=2)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Cumulative Realized PnL (units)\")\n",
    "    plt.grid(True, linewidth=0.5, alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outfile, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    # Small summary for the report header if you need it\n",
    "    summary = res[\"summary\"]\n",
    "    print(\"Saved chart to:\", outfile)\n",
    "    print(\n",
    "        f\"Summary â†’ Total PnL: {summary.get('total_pnl_units', 0):.4f} | \"\n",
    "        f\"Trades: {summary.get('num_trades', 0)} | \"\n",
    "        f\"Hit Ratio: {summary.get('hit_ratio', float('nan'))} | \"\n",
    "        f\"Avg Hold (days): {summary.get('avg_hold_days', float('nan'))}\"\n",
    "    )\n",
    "\n",
    "# -------------------- Example: run backtest + plot --------------------\n",
    "# NOTE: Uncomment the two lines below and run on a Bloomberg-enabled machine (with the earlier backtester code loaded).\n",
    "\n",
    "# res = backtest_parity(\n",
    "#     underlying=\"AAPL US Equity\", start=\"20240101\", end=\"20240930\",\n",
    "#     min_dte=25, max_dte=45, gap_threshold=0.10\n",
    "# )\n",
    "# plot_backtest(res, title=\"AAPL Parity Arbitrage Backtest (2024YTD)\", outfile=\"aapl_parity_backtest.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d78d3f3-a794-43c7-9004-e55114cc6dae",
   "metadata": {},
   "source": [
    "### ðŸ‡§ðŸ‡· Brazilian Equities â€” Bloomberg Tickers\r\n",
    "\r\n",
    "| Company               | B3 Ticker | Bloomberg Ticker        |\r\n",
    "|------------------------|------------|----------------------------|\r\n",
    "| Vale                   | VALE3      | `VALE3 BZ Equity`          |\r\n",
    "| Petrobras (PN)         | PETR4      | `PETR4 BZ Equity`          |\r\n",
    "| Embraer                 | EMBR3      | `EMBR3 BZ Equity`          |\r\n",
    "| Banco do Brasil         | BBAS3      | `BBAS3 BZ Equity`          |\r\n",
    "| Bradesco (PN)            | BBDC4      | `BBDC4 BZ Equity`          |\r\n",
    "| ItaÃº Unibanco (PN)       | ITUB4      | `ITUB4 BZ Equity`          |\r\n",
    "| Ambev                    | ABEV3      | `ABEV3 BZ Equity`          |\r\n",
    "| Magazine Luiza           | MGLU3      | `MGLU3 BZ Equity`          |\r\n",
    "| Suzano                    | SUZB3      | `SUZB3 BZ Equity`          |\r\n",
    "| Gerdau                     | GGBR4      | `GGBR4 BZ Equity`          |\r\n",
    "| Eletrobras                   | ELET3      | `ELET3 BZ Equity`          |\r\n",
    "| Weg                           | WEGE3      | `WEGE3 BZ Equity`          |\r\n",
    "| Localiza                       | RENT3      | `RENT3 BZ Equity`          |\r\n",
    "| B3 (stock exchange)                | B3SA3      | `B3SA3 BZ Equity`          |\r\n",
    "| Lojas Renner                                   | LREN3      | `LREN3 BZ Equity`          |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5df9fef-2bb7-46c6-86ee-79dbd9dbf26a",
   "metadata": {},
   "source": [
    "## New Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f64c76a-d3dd-48b2-bc2f-c7ed20950561",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Element' object has no attribute 'getElementAsFloat64'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 290\u001b[0m\n\u001b[0;32m    287\u001b[0m min_dte, max_dte \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m, \u001b[38;5;241m45\u001b[39m\n\u001b[0;32m    288\u001b[0m gap_threshold    \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.10\u001b[39m\n\u001b[1;32m--> 290\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mbacktest_parity\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43munderlying\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munderlying\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_dte\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_dte\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_dte\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_dte\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgap_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgap_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mriskfree_ticker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBZSELIC Index\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# for BRL, try \"BZSELIC Index\" if available\u001b[39;49;00m\n\u001b[0;32m    298\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummary:\u001b[39m\u001b[38;5;124m\"\u001b[39m, res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFirst trades:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrades\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mhead())\n",
      "Cell \u001b[1;32mIn[19], line 184\u001b[0m, in \u001b[0;36mbacktest_parity\u001b[1;34m(underlying, start, end, min_dte, max_dte, gap_threshold, max_hold_days, riskfree_ticker)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbacktest_parity\u001b[39m(\n\u001b[0;32m    176\u001b[0m     underlying\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAAPL US Equity\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    177\u001b[0m     start\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m20240101\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m     riskfree_ticker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSGG3M Index\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# for BRL try \"BZSELIC Index\" if available\u001b[39;00m\n\u001b[0;32m    183\u001b[0m ):\n\u001b[1;32m--> 184\u001b[0m     px \u001b[38;5;241m=\u001b[39m \u001b[43mget_bdh_equity\u001b[49m\u001b[43m(\u001b[49m\u001b[43munderlying\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPX_LAST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m     rf \u001b[38;5;241m=\u001b[39m get_riskfree_series(start, end, ticker\u001b[38;5;241m=\u001b[39mriskfree_ticker)\n\u001b[0;32m    186\u001b[0m     df \u001b[38;5;241m=\u001b[39m px\u001b[38;5;241m.\u001b[39mjoin(rf, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mfillna(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mffill\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[19], line 52\u001b[0m, in \u001b[0;36mget_bdh_equity\u001b[1;34m(symbol_bbg, start_yyyymmdd, end_yyyymmdd, fields, periodicity)\u001b[0m\n\u001b[0;32m     50\u001b[0m         out \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m: pd\u001b[38;5;241m.\u001b[39mto_datetime(d\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))}\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fields:\n\u001b[1;32m---> 52\u001b[0m             out[f] \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetElementAsFloat64\u001b[49m(f) \u001b[38;5;28;01mif\u001b[39;00m row\u001b[38;5;241m.\u001b[39mhasElement(f) \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan\n\u001b[0;32m     53\u001b[0m         rows\u001b[38;5;241m.\u001b[39mappend(out)\n\u001b[0;32m     54\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(rows)\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Element' object has no attribute 'getElementAsFloat64'"
     ]
    }
   ],
   "source": [
    "# ======================= ALL-IN-ONE: Bloomberg loader + backtest + plot + example run =======================\n",
    "# Requirements in this kernel: blpapi, pandas, numpy, scipy, matplotlib\n",
    "# Run on a Bloomberg Terminal PC (Desktop API; localhost:8194)\n",
    "\n",
    "import blpapi, pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------- Bloomberg session helpers --------------------\n",
    "def _start_bbg_session(host=\"localhost\", port=8194):\n",
    "    so = blpapi.SessionOptions()\n",
    "    so.setServerHost(host); so.setServerPort(port)\n",
    "    s = blpapi.Session(so)\n",
    "    if not s.start(): raise RuntimeError(\"Failed to start Bloomberg session.\")\n",
    "    if not s.openService(\"//blp/refdata\"): raise RuntimeError(\"Failed to open //blp/refdata.\")\n",
    "    return s, s.getService(\"//blp/refdata\")\n",
    "\n",
    "def _send_req(session, req, timeout_ms=120_000):\n",
    "    session.sendRequest(req)\n",
    "    msgs = []\n",
    "    while True:\n",
    "        ev = session.nextEvent(timeout_ms)\n",
    "        for m in ev: msgs.append(m)\n",
    "        if ev.eventType() == blpapi.Event.RESPONSE:\n",
    "            break\n",
    "    return msgs\n",
    "\n",
    "# -------------------- BDH: historical for any security (e.g., equity, rates) --------------------\n",
    "def get_bdh_equity(symbol_bbg, start_yyyymmdd, end_yyyymmdd, fields=(\"PX_LAST\",), periodicity=\"DAILY\"):\n",
    "    s, ref = _start_bbg_session()\n",
    "    try:\n",
    "        r = ref.createRequest(\"HistoricalDataRequest\")\n",
    "        r.getElement(\"securities\").appendValue(symbol_bbg)\n",
    "        fe = r.getElement(\"fields\")\n",
    "        for f in fields: fe.appendValue(f)\n",
    "        r.set(\"startDate\", start_yyyymmdd)\n",
    "        r.set(\"endDate\", end_yyyymmdd)\n",
    "        r.set(\"periodicitySelection\", periodicity)\n",
    "        msgs = _send_req(s, r)\n",
    "\n",
    "        rows = []\n",
    "        for msg in msgs:\n",
    "            if not msg.hasElement(\"securityData\"): continue\n",
    "            sd = msg.getElement(\"securityData\")\n",
    "            fd = sd.getElement(\"fieldData\")\n",
    "            for i in range(fd.numValues()):\n",
    "                row = fd.getValueAsElement(i)\n",
    "                d = row.getElementAsDatetime(\"date\")\n",
    "                out = {\"date\": pd.to_datetime(d.strftime(\"%Y-%m-%d\"))}\n",
    "                for f in fields:\n",
    "                    out[f] = row.getElementAsFloat64(f) if row.hasElement(f) else np.nan\n",
    "                rows.append(out)\n",
    "        df = pd.DataFrame(rows).sort_values(\"date\").set_index(\"date\")\n",
    "        return df\n",
    "    finally:\n",
    "        s.stop()\n",
    "\n",
    "def get_riskfree_series(start_yyyymmdd, end_yyyymmdd, ticker=\"USGG3M Index\"):\n",
    "    \"\"\"Risk-free proxy. For Brazil you can try 'BZSELIC Index' if available on your terminal.\"\"\"\n",
    "    rf = get_bdh_equity(ticker, start_yyyymmdd, end_yyyymmdd, fields=(\"PX_LAST\",))\n",
    "    rf = rf.rename(columns={\"PX_LAST\": \"RF_YLD_PCT\"})\n",
    "    rf[\"rf_daily\"] = (rf[\"RF_YLD_PCT\"]/100.0)/365.0  # simple daily approx\n",
    "    return rf[[\"rf_daily\"]]\n",
    "\n",
    "# -------------------- Option chain (BDS CHAIN_TICKERS + BDP per-option fields) --------------------\n",
    "def get_chain_for_day(underlying_bbg, spot_px, trade_date, target_min_dte=25, target_max_dte=45, max_points=600):\n",
    "    s, ref = _start_bbg_session()\n",
    "    try:\n",
    "        expiries = []\n",
    "        base = trade_date + timedelta(days=(target_min_dte + target_max_dte)//2)\n",
    "        for k in range(-21, 22, 7):  # probe +/- 3 weeks around the target month\n",
    "            expiries.append((base + timedelta(days=k)).strftime(\"%Y%m%d\"))\n",
    "        expiries = list(dict.fromkeys(expiries))\n",
    "\n",
    "        best_rows = []\n",
    "        for exp in expiries:\n",
    "            bds = ref.createRequest(\"ReferenceDataRequest\")\n",
    "            bds.getElement(\"securities\").appendValue(underlying_bbg)\n",
    "            bds.getElement(\"fields\").appendValue(\"CHAIN_TICKERS\")\n",
    "            ov = bds.getElement(\"overrides\")\n",
    "            o1 = ov.appendElement(); o1.setElement(\"fieldId\",\"CHAIN_EXP_DT_OVRD\");   o1.setElement(\"value\",exp)\n",
    "            o2 = ov.appendElement(); o2.setElement(\"fieldId\",\"CHAIN_POINTS_LIMIT\"); o2.setElement(\"value\",str(max_points))\n",
    "            msgs = _send_req(s, bds)\n",
    "\n",
    "            tickers = []\n",
    "            for msg in msgs:\n",
    "                if not msg.hasElement(\"securityData\"): continue\n",
    "                sdata = msg.getElement(\"securityData\").getValueAsElement(0)\n",
    "                fdata = sdata.getElement(\"fieldData\") if sdata.hasElement(\"fieldData\") else None\n",
    "                if fdata is None or not fdata.hasElement(\"CHAIN_TICKERS\"): continue\n",
    "                bulk = fdata.getElement(\"CHAIN_TICKERS\")\n",
    "                for i in range(bulk.numValues()):\n",
    "                    e = bulk.getValueAsElement(i)\n",
    "                    if e.hasElement(\"Ticker\"):\n",
    "                        tickers.append(e.getElementAsString(\"Ticker\"))\n",
    "            if not tickers:\n",
    "                continue\n",
    "\n",
    "            # BDP on chain\n",
    "            fields = [\"PX_BID\",\"PX_ASK\",\"IMPLIED_VOLATILITY\",\"DELTA\",\"GAMMA\",\"THETA\",\"VEGA\",\n",
    "                      \"OPT_STRIKE_PX\",\"OPT_EXPIRE_DT\",\"OPT_PUT_CALL\",\"OPT_UNDL_PX\"]\n",
    "            bdp = ref.createRequest(\"ReferenceDataRequest\")\n",
    "            se = bdp.getElement(\"securities\"); [se.appendValue(t) for t in tickers]\n",
    "            fe = bdp.getElement(\"fields\");     [fe.appendValue(f) for f in fields]\n",
    "            msgs2 = _send_req(s, bdp)\n",
    "\n",
    "            rows = []\n",
    "            for msg in msgs2:\n",
    "                if not msg.hasElement(\"securityData\"): continue\n",
    "                arr = msg.getElement(\"securityData\")\n",
    "                for i in range(arr.numValues()):\n",
    "                    e = arr.getValueAsElement(i)\n",
    "                    sec = e.getElementAsString(\"security\")\n",
    "                    fdata = e.getElement(\"fieldData\")\n",
    "                    row = {\"security\": sec}\n",
    "                    for f in fields:\n",
    "                        if fdata.hasElement(f):\n",
    "                            try: row[f] = fdata.getElementAsFloat64(f)\n",
    "                            except Exception:\n",
    "                                try: row[f] = fdata.getElementAsString(f)\n",
    "                                except Exception: row[f] = np.nan\n",
    "                    rows.append(row)\n",
    "            df = pd.DataFrame(rows)\n",
    "            if df.empty:\n",
    "                continue\n",
    "            df[\"OPT_EXPIRE_DT\"] = pd.to_datetime(df[\"OPT_EXPIRE_DT\"], errors=\"coerce\")\n",
    "            df[\"OPT_STRIKE_PX\"] = pd.to_numeric(df[\"OPT_STRIKE_PX\"], errors=\"coerce\")\n",
    "            df[\"OPT_PUT_CALL\"]  = df[\"OPT_PUT_CALL\"].astype(str).str.upper()\n",
    "            df[\"DTE\"] = (df[\"OPT_EXPIRE_DT\"] - pd.Timestamp(trade_date)).dt.days\n",
    "            df = df[(df[\"DTE\"]>=target_min_dte) & (df[\"DTE\"]<=target_max_dte)].copy()\n",
    "            if df.empty:\n",
    "                continue\n",
    "            df[\"MID\"] = (pd.to_numeric(df[\"PX_BID\"], errors=\"coerce\") + pd.to_numeric(df[\"PX_ASK\"], errors=\"coerce\"))/2.0\n",
    "            df[\"spot_for_day\"] = spot_px\n",
    "            best_rows.append(df)\n",
    "\n",
    "        if not best_rows:\n",
    "            return pd.DataFrame()\n",
    "        chain = pd.concat(best_rows, ignore_index=True).dropna(subset=[\"OPT_STRIKE_PX\",\"MID\",\"OPT_PUT_CALL\",\"OPT_EXPIRE_DT\"])\n",
    "        # choose ATM call+put (closest strike to spot) among the kept expiries\n",
    "        chain[\"atm_dist\"] = (chain[\"OPT_STRIKE_PX\"] - spot_px).abs()\n",
    "        atm_calls = chain[chain[\"OPT_PUT_CALL\"]==\"C\"].sort_values([\"atm_dist\",\"DTE\"]).groupby(\"OPT_EXPIRE_DT\").head(1)\n",
    "        atm_puts  = chain[chain[\"OPT_PUT_CALL\"]==\"P\"].sort_values([\"atm_dist\",\"DTE\"]).groupby(\"OPT_EXPIRE_DT\").head(1)\n",
    "        pairs = atm_calls.merge(atm_puts, on=\"OPT_EXPIRE_DT\", suffixes=(\"_C\",\"_P\"))\n",
    "        if pairs.empty:\n",
    "            return pd.DataFrame()\n",
    "        pairs[\"combo_dist\"] = pairs[\"atm_dist_C\"] + pairs[\"atm_dist_P\"]\n",
    "        best = pairs.sort_values([\"combo_dist\",\"DTE_C\"]).head(1)\n",
    "        return pd.DataFrame([{\n",
    "            \"expiry\":   best[\"OPT_EXPIRE_DT\"].iloc[0],\n",
    "            \"DTE\":      int(best[\"DTE_C\"].iloc[0]),\n",
    "            \"call_tkr\": best[\"security_C\"].iloc[0],\n",
    "            \"put_tkr\":  best[\"security_P\"].iloc[0],\n",
    "            \"K\":        float(best[\"OPT_STRIKE_PX_C\"].iloc[0]),\n",
    "            \"C_mid\":    float(best[\"MID_C\"].iloc[0]),\n",
    "            \"P_mid\":    float(best[\"MID_P\"].iloc[0]),\n",
    "            \"IV_call\":  float(best[\"IMPLIED_VOLATILITY_C\"].iloc[0]) if pd.notna(best[\"IMPLIED_VOLATILITY_C\"].iloc[0]) else np.nan,\n",
    "            \"IV_put\":   float(best[\"IMPLIED_VOLATILITY_P\"].iloc[0]) if pd.notna(best[\"IMPLIED_VOLATILITY_P\"].iloc[0]) else np.nan\n",
    "        }])\n",
    "    finally:\n",
    "        s.stop()\n",
    "\n",
    "# -------------------- Quant helpers --------------------\n",
    "def black_scholes_price(S, K, T, r, sigma, cp):\n",
    "    d1 = (np.log(S/K) + (r + 0.5*sigma*sigma)*T)/(sigma*np.sqrt(T))\n",
    "    d2 = d1 - sigma*np.sqrt(T)\n",
    "    return (S*norm.cdf(d1) - K*np.exp(-r*T)*norm.cdf(d2)) if cp.upper()==\"C\" else (K*np.exp(-r*T)*norm.cdf(-d2) - S*norm.cdf(-d1))\n",
    "\n",
    "def realized_vol_from_close(close):\n",
    "    ret = np.log(close/close.shift(1)).dropna()\n",
    "    return ret.rolling(21).std()*np.sqrt(252)\n",
    "\n",
    "# -------------------- The backtest --------------------\n",
    "def backtest_parity(\n",
    "    underlying=\"AAPL US Equity\",\n",
    "    start=\"20240101\",\n",
    "    end  =\"20240930\",\n",
    "    min_dte=25, max_dte=45,\n",
    "    gap_threshold=0.10,\n",
    "    max_hold_days=60,\n",
    "    riskfree_ticker=\"USGG3M Index\"  # for BRL try \"BZSELIC Index\" if available\n",
    "):\n",
    "    px = get_bdh_equity(underlying, start, end, fields=(\"PX_LAST\",))\n",
    "    rf = get_riskfree_series(start, end, ticker=riskfree_ticker)\n",
    "    df = px.join(rf, how=\"left\").fillna(method=\"ffill\")\n",
    "    df[\"rv_21\"] = realized_vol_from_close(df[\"PX_LAST\"])\n",
    "\n",
    "    trades, equity_curve = [], []\n",
    "    open_pos = None\n",
    "\n",
    "    for dt, row in df.iterrows():\n",
    "        S = row[\"PX_LAST\"]\n",
    "        rf_day = float(row[\"rf_daily\"]) if pd.notna(row.get(\"rf_daily\", np.nan)) else 0.0\n",
    "\n",
    "        if open_pos:\n",
    "            open_pos[\"days_held\"] += 1\n",
    "            open_pos[\"cash\"] *= (1.0 + rf_day)\n",
    "            equity_curve.append({\"date\": dt, \"equity\": open_pos[\"equity_mark\"]})\n",
    "        else:\n",
    "            equity_curve.append({\"date\": dt, \"equity\": 0.0})\n",
    "\n",
    "        if open_pos:\n",
    "            if dt >= open_pos[\"expiry\"] or open_pos[\"days_held\"] >= max_hold_days:\n",
    "                pnl = open_pos[\"gap_signed\"]  # simple convergence realization\n",
    "                trades.append({**open_pos, \"exit_date\": dt, \"pnl\": pnl})\n",
    "                open_pos = None\n",
    "            continue\n",
    "\n",
    "        chain = get_chain_for_day(underlying, S, dt, min_dte, max_dte)\n",
    "        if chain.empty:\n",
    "            continue\n",
    "\n",
    "        K    = chain[\"K\"].iloc[0]\n",
    "        Cmid = chain[\"C_mid\"].iloc[0]\n",
    "        Pmid = chain[\"P_mid\"].iloc[0]\n",
    "        expiry = chain[\"expiry\"].iloc[0]\n",
    "        dte   = int(chain[\"DTE\"].iloc[0])\n",
    "        T     = dte/365.0\n",
    "\n",
    "        r_ann = df.loc[:dt].tail(1)[\"rf_daily\"].iloc[0]*365.0 if \"rf_daily\" in df.columns else 0.0\n",
    "        dfac  = np.exp(-r_ann*T)\n",
    "        gap   = (Cmid - Pmid) - (S - K*dfac)\n",
    "\n",
    "        if abs(gap) < gap_threshold:\n",
    "            continue\n",
    "\n",
    "        direction = \"short_call_long_put_shortS_longB\" if gap > 0 else \"long_call_short_put_longS_shortB\"\n",
    "        open_pos = {\n",
    "            \"entry_date\": dt, \"expiry\": expiry, \"days_held\": 0,\n",
    "            \"underlying\": underlying,\n",
    "            \"S0\": S, \"K\": K, \"C_mid0\": Cmid, \"P_mid0\": Pmid,\n",
    "            \"r_ann\": r_ann, \"T\": T, \"dte\": dte,\n",
    "            \"gap\": float(gap), \"gap_signed\": float(np.sign(gap)*abs(gap)),\n",
    "            \"direction\": direction,\n",
    "            \"cash\": K*dfac if gap>0 else -K*dfac,\n",
    "            \"equity_mark\": float(np.sign(gap)*abs(gap))\n",
    "        }\n",
    "\n",
    "    eq = pd.DataFrame(equity_curve).set_index(\"date\")\n",
    "    tr = pd.DataFrame(trades)\n",
    "\n",
    "    if not tr.empty:\n",
    "        total_pnl = tr[\"pnl\"].sum()\n",
    "        hitrate   = (tr[\"pnl\"]>0).mean()\n",
    "        avg_hold  = tr[\"days_held\"].mean()\n",
    "    else:\n",
    "        total_pnl = 0.0; hitrate = np.nan; avg_hold = np.nan\n",
    "\n",
    "    return {\n",
    "        \"underlying_history\": df,\n",
    "        \"equity_curve\": eq,\n",
    "        \"trades\": tr,\n",
    "        \"summary\": {\n",
    "            \"total_pnl_units\": float(total_pnl),\n",
    "            \"num_trades\": int(len(tr)),\n",
    "            \"hit_ratio\": float(hitrate) if pd.notna(hitrate) else None,\n",
    "            \"avg_hold_days\": float(avg_hold) if pd.notna(avg_hold) else None\n",
    "        }\n",
    "    }\n",
    "\n",
    "# -------------------- Plot helper (saves PNG) --------------------\n",
    "def plot_backtest(res, title=\"Parity Arbitrage Backtest\", outfile=None):\n",
    "    uh = res[\"underlying_history\"].copy()\n",
    "    tr = res[\"trades\"].copy() if not res[\"trades\"].empty else pd.DataFrame(columns=[\"exit_date\",\"pnl\"])\n",
    "    daily = pd.Series(0.0, index=uh.index)\n",
    "    if not tr.empty:\n",
    "        tr = tr.set_index(\"exit_date\").sortindex() if hasattr(tr, \"sortindex\") else tr.set_index(\"exit_date\").sort_index()\n",
    "        for dt, row in tr.iterrows():\n",
    "            if dt in daily.index:\n",
    "                daily.loc[dt] += float(row[\"pnl\"])\n",
    "    cum_pnl = daily.cumsum()\n",
    "    if outfile is None:\n",
    "        outfile = Path(f\"./backtest_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\")\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(cum_pnl.index, cum_pnl.values, linewidth=2)\n",
    "    plt.title(title); plt.xlabel(\"Date\"); plt.ylabel(\"Cumulative Realized PnL (units)\")\n",
    "    plt.grid(True, linewidth=0.5, alpha=0.6); plt.tight_layout()\n",
    "    plt.savefig(outfile, dpi=200); plt.close()\n",
    "    print(\"Saved chart to:\", outfile)\n",
    "\n",
    "# -------------------- Example run (edit ticker/dates and run the cell) --------------------\n",
    "underlying = \"VALE3 BZ Equity\"   # ex: \"PETR4 BZ Equity\", \"AAPL US Equity\"\n",
    "start      = \"20240101\"\n",
    "end        = datetime.today().strftime(\"%Y%m%d\")\n",
    "min_dte, max_dte = 25, 45\n",
    "gap_threshold    = 0.10\n",
    "\n",
    "res = backtest_parity(\n",
    "    underlying=underlying,\n",
    "    start=start,\n",
    "    end=end,\n",
    "    min_dte=min_dte,\n",
    "    max_dte=max_dte,\n",
    "    gap_threshold=gap_threshold,\n",
    "    riskfree_ticker=\"BZSELIC Index\"  # for BRL, try \"BZSELIC Index\" if available\n",
    ")\n",
    "print(\"Summary:\", res[\"summary\"])\n",
    "print(\"\\nFirst trades:\\n\", res[\"trades\"].head())\n",
    "\n",
    "outfile = f\"{underlying.replace(' ','_')}_parity_backtest.png\"\n",
    "plot_backtest(res, title=f\"{underlying} Parity Arbitrage Backtest\", outfile=outfile)\n",
    "print(f\"Chart saved to: {outfile}\")\n",
    "# ===========================================================================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a91ccacf-0afd-4e3d-b396-6882688f3233",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antoniovd\\AppData\\Local\\Temp\\ipykernel_26964\\1702782002.py:97: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[f] = pd.to_numeric(df[f], errors=\"ignore\")\n",
      "C:\\Users\\antoniovd\\AppData\\Local\\Temp\\ipykernel_26964\\1702782002.py:242: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = px.join(rf, how=\"left\").fillna(method=\"ffill\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: {'total_pnl_units': 0.0, 'num_trades': 0, 'hit_ratio': None, 'avg_hold_days': None}\n",
      "\n",
      "First trades:\n",
      " Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Saved chart to: VALE3_BZ_Equity_parity_backtest.png\n",
      "Chart saved to: VALE3_BZ_Equity_parity_backtest.png\n"
     ]
    }
   ],
   "source": [
    "# ======================= ALL-IN-ONE (FIXED): Bloomberg loader + backtest + plot + example run =======================\n",
    "# Requirements in this kernel: blpapi, pandas, numpy, scipy, matplotlib\n",
    "# Run on a Bloomberg Terminal PC (Desktop API; localhost:8194)\n",
    "\n",
    "import blpapi, pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------- Bloomberg session helpers --------------------\n",
    "def _start_bbg_session(host=\"localhost\", port=8194):\n",
    "    so = blpapi.SessionOptions()\n",
    "    so.setServerHost(host); so.setServerPort(port)\n",
    "    s = blpapi.Session(so)\n",
    "    if not s.start(): raise RuntimeError(\"Failed to start Bloomberg session.\")\n",
    "    if not s.openService(\"//blp/refdata\"): raise RuntimeError(\"Failed to open //blp/refdata.\")\n",
    "    return s, s.getService(\"//blp/refdata\")\n",
    "\n",
    "def _send_req(session, req, timeout_ms=120_000):\n",
    "    session.sendRequest(req)\n",
    "    msgs = []\n",
    "    while True:\n",
    "        ev = session.nextEvent(timeout_ms)\n",
    "        for m in ev: msgs.append(m)\n",
    "        if ev.eventType() == blpapi.Event.RESPONSE:\n",
    "            break\n",
    "    return msgs\n",
    "\n",
    "# -------------------- Safe extractor for blpapi.Element --------------------\n",
    "def _blp_get(parent_el: blpapi.Element, field_name: str):\n",
    "    \"\"\"\n",
    "    Safely extract a field value from a blpapi Element (parent_el).\n",
    "    Returns np.nan if absent. Converts blpapi.Datetime to pandas.Timestamp.\n",
    "    \"\"\"\n",
    "    if not parent_el.hasElement(field_name):\n",
    "        return np.nan\n",
    "    sub = parent_el.getElement(field_name)\n",
    "\n",
    "    # Try numeric first\n",
    "    for meth in (\"getValueAsFloat64\", \"getValueAsInt64\", \"getValueAsInteger\"):\n",
    "        try:\n",
    "            return getattr(sub, meth)()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Bool / Datetime / String\n",
    "    for meth in (\"getValueAsBool\", \"getValueAsDatetime\", \"getValueAsString\"):\n",
    "        try:\n",
    "            val = getattr(sub, meth)()\n",
    "            if isinstance(val, blpapi.Datetime):\n",
    "                # Convert Bloomberg Datetime to pandas Timestamp (date-only)\n",
    "                return pd.to_datetime(val.strftime(\"%Y-%m-%d\"))\n",
    "            return val\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Final fallback\n",
    "    try:\n",
    "        return sub.getValue()\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "# -------------------- BDH: historical for any security (e.g., equity, rates) --------------------\n",
    "def get_bdh_equity(symbol_bbg, start_yyyymmdd, end_yyyymmdd, fields=(\"PX_LAST\",), periodicity=\"DAILY\"):\n",
    "    s, ref = _start_bbg_session()\n",
    "    try:\n",
    "        r = ref.createRequest(\"HistoricalDataRequest\")\n",
    "        r.getElement(\"securities\").appendValue(symbol_bbg)\n",
    "        fe = r.getElement(\"fields\")\n",
    "        for f in fields: fe.appendValue(f)\n",
    "        r.set(\"startDate\", start_yyyymmdd)\n",
    "        r.set(\"endDate\", end_yyyymmdd)\n",
    "        r.set(\"periodicitySelection\", periodicity)\n",
    "        msgs = _send_req(s, r)\n",
    "\n",
    "        rows = []\n",
    "        for msg in msgs:\n",
    "            if not msg.hasElement(\"securityData\"): continue\n",
    "            sd = msg.getElement(\"securityData\")\n",
    "            if not sd.hasElement(\"fieldData\"): continue\n",
    "            fd = sd.getElement(\"fieldData\")\n",
    "            for i in range(fd.numValues()):\n",
    "                row_el = fd.getValueAsElement(i)\n",
    "                d = row_el.getElementAsDatetime(\"date\")\n",
    "                out = {\"date\": pd.to_datetime(d.strftime(\"%Y-%m-%d\"))}\n",
    "                for f in fields:\n",
    "                    val = _blp_get(row_el, f)\n",
    "                    out[f] = val if val is not None else np.nan\n",
    "                rows.append(out)\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "        if df.empty:\n",
    "            return pd.DataFrame(columns=list(fields)).astype(float)\n",
    "        df = df.sort_values(\"date\").set_index(\"date\")\n",
    "        # best effort: coerce numerics\n",
    "        for f in fields:\n",
    "            df[f] = pd.to_numeric(df[f], errors=\"ignore\")\n",
    "        return df\n",
    "    finally:\n",
    "        s.stop()\n",
    "\n",
    "# -------------------- Helper: parse BDP messages to DataFrame --------------------\n",
    "def _parse_bdp_messages_to_df(msgs, fields):\n",
    "    rows = []\n",
    "    for msg in msgs:\n",
    "        if not msg.hasElement(\"securityData\"):\n",
    "            continue\n",
    "        sdata = msg.getElement(\"securityData\")\n",
    "        for i in range(sdata.numValues()):\n",
    "            e = sdata.getValueAsElement(i)\n",
    "            sec = e.getElementAsString(\"security\")\n",
    "            if not e.hasElement(\"fieldData\"):\n",
    "                continue\n",
    "            fdata = e.getElement(\"fieldData\")\n",
    "            row = {\"security\": sec}\n",
    "            for f in fields:\n",
    "                val = _blp_get(fdata, f)\n",
    "                row[f] = val if val is not None else np.nan\n",
    "            rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# -------------------- Option chain (BDS CHAIN_TICKERS + BDP per-option fields) --------------------\n",
    "def get_chain_for_day(underlying_bbg, spot_px, trade_date, target_min_dte=25, target_max_dte=45, max_points=600):\n",
    "    s, ref = _start_bbg_session()\n",
    "    try:\n",
    "        # Probe expiries around ~1 month\n",
    "        expiries = []\n",
    "        base = trade_date + timedelta(days=(target_min_dte + target_max_dte)//2)\n",
    "        for k in range(-21, 22, 7):  # Â±3 weeks\n",
    "            expiries.append((base + timedelta(days=k)).strftime(\"%Y%m%d\"))\n",
    "        expiries = list(dict.fromkeys(expiries))\n",
    "\n",
    "        best_rows = []\n",
    "        for exp in expiries:\n",
    "            # BDS: CHAIN_TICKERS\n",
    "            bds = ref.createRequest(\"ReferenceDataRequest\")\n",
    "            bds.getElement(\"securities\").appendValue(underlying_bbg)\n",
    "            bds.getElement(\"fields\").appendValue(\"CHAIN_TICKERS\")\n",
    "            ov = bds.getElement(\"overrides\")\n",
    "            o1 = ov.appendElement(); o1.setElement(\"fieldId\",\"CHAIN_EXP_DT_OVRD\");   o1.setElement(\"value\",exp)\n",
    "            o2 = ov.appendElement(); o2.setElement(\"fieldId\",\"CHAIN_POINTS_LIMIT\"); o2.setElement(\"value\",str(max_points))\n",
    "            msgs = _send_req(s, bds)\n",
    "\n",
    "            tickers = []\n",
    "            for msg in msgs:\n",
    "                if not msg.hasElement(\"securityData\"): continue\n",
    "                arr = msg.getElement(\"securityData\")\n",
    "                for i in range(arr.numValues()):\n",
    "                    sd = arr.getValueAsElement(i)\n",
    "                    if not sd.hasElement(\"fieldData\"): continue\n",
    "                    fdata = sd.getElement(\"fieldData\")\n",
    "                    if not fdata.hasElement(\"CHAIN_TICKERS\"): continue\n",
    "                    bulk = fdata.getElement(\"CHAIN_TICKERS\")\n",
    "                    for j in range(bulk.numValues()):\n",
    "                        e = bulk.getValueAsElement(j)\n",
    "                        if e.hasElement(\"Ticker\"):\n",
    "                            tickers.append(e.getElementAsString(\"Ticker\"))\n",
    "\n",
    "            if not tickers:\n",
    "                continue\n",
    "\n",
    "            # BDP: per-option fields\n",
    "            fields = [\"PX_BID\",\"PX_ASK\",\"IMPLIED_VOLATILITY\",\"DELTA\",\"GAMMA\",\"THETA\",\"VEGA\",\n",
    "                      \"OPT_STRIKE_PX\",\"OPT_EXPIRE_DT\",\"OPT_PUT_CALL\",\"OPT_UNDL_PX\"]\n",
    "            bdp = ref.createRequest(\"ReferenceDataRequest\")\n",
    "            se = bdp.getElement(\"securities\"); [se.appendValue(t) for t in tickers]\n",
    "            fe = bdp.getElement(\"fields\");     [fe.appendValue(f) for f in fields]\n",
    "            msgs2 = _send_req(s, bdp)\n",
    "\n",
    "            df = _parse_bdp_messages_to_df(msgs2, fields)\n",
    "            if df.empty:\n",
    "                continue\n",
    "\n",
    "            # Clean up & filter\n",
    "            df[\"OPT_EXPIRE_DT\"] = pd.to_datetime(df[\"OPT_EXPIRE_DT\"], errors=\"coerce\")\n",
    "            df[\"OPT_STRIKE_PX\"] = pd.to_numeric(df[\"OPT_STRIKE_PX\"], errors=\"coerce\")\n",
    "            df[\"OPT_PUT_CALL\"]  = df[\"OPT_PUT_CALL\"].astype(str).str.upper()\n",
    "            df[\"DTE\"] = (df[\"OPT_EXPIRE_DT\"] - pd.Timestamp(trade_date)).dt.days\n",
    "            df = df[(df[\"DTE\"]>=target_min_dte) & (df[\"DTE\"]<=target_max_dte)].copy()\n",
    "            if df.empty:\n",
    "                continue\n",
    "            df[\"PX_BID\"] = pd.to_numeric(df[\"PX_BID\"], errors=\"coerce\")\n",
    "            df[\"PX_ASK\"] = pd.to_numeric(df[\"PX_ASK\"], errors=\"coerce\")\n",
    "            df[\"MID\"] = (df[\"PX_BID\"] + df[\"PX_ASK\"])/2.0\n",
    "            df[\"spot_for_day\"] = spot_px\n",
    "            best_rows.append(df)\n",
    "\n",
    "        if not best_rows:\n",
    "            return pd.DataFrame()\n",
    "        chain = pd.concat(best_rows, ignore_index=True).dropna(subset=[\"OPT_STRIKE_PX\",\"MID\",\"OPT_PUT_CALL\",\"OPT_EXPIRE_DT\"])\n",
    "        # choose ATM call+put (closest strike to spot) among the kept expiries\n",
    "        chain[\"atm_dist\"] = (chain[\"OPT_STRIKE_PX\"] - spot_px).abs()\n",
    "        atm_calls = chain[chain[\"OPT_PUT_CALL\"]==\"C\"].sort_values([\"atm_dist\",\"DTE\"]).groupby(\"OPT_EXPIRE_DT\").head(1)\n",
    "        atm_puts  = chain[chain[\"OPT_PUT_CALL\"]==\"P\"].sort_values([\"atm_dist\",\"DTE\"]).groupby(\"OPT_EXPIRE_DT\").head(1)\n",
    "        pairs = atm_calls.merge(atm_puts, on=\"OPT_EXPIRE_DT\", suffixes=(\"_C\",\"_P\"))\n",
    "        if pairs.empty:\n",
    "            return pd.DataFrame()\n",
    "        pairs[\"combo_dist\"] = pairs[\"atm_dist_C\"] + pairs[\"atm_dist_P\"]\n",
    "        best = pairs.sort_values([\"combo_dist\",\"DTE_C\"]).head(1)\n",
    "        return pd.DataFrame([{\n",
    "            \"expiry\":   best[\"OPT_EXPIRE_DT\"].iloc[0],\n",
    "            \"DTE\":      int(best[\"DTE_C\"].iloc[0]),\n",
    "            \"call_tkr\": best[\"security_C\"].iloc[0],\n",
    "            \"put_tkr\":  best[\"security_P\"].iloc[0],\n",
    "            \"K\":        float(best[\"OPT_STRIKE_PX_C\"].iloc[0]),\n",
    "            \"C_mid\":    float(best[\"MID_C\"].iloc[0]),\n",
    "            \"P_mid\":    float(best[\"MID_P\"].iloc[0]),\n",
    "            \"IV_call\":  float(best[\"IMPLIED_VOLATILITY_C\"].iloc[0]) if pd.notna(best[\"IMPLIED_VOLATILITY_C\"].iloc[0]) else np.nan,\n",
    "            \"IV_put\":   float(best[\"IMPLIED_VOLATILITY_P\"].iloc[0]) if pd.notna(best[\"IMPLIED_VOLATILITY_P\"].iloc[0]) else np.nan\n",
    "        }])\n",
    "    finally:\n",
    "        s.stop()\n",
    "\n",
    "# -------------------- Quant helpers --------------------\n",
    "def black_scholes_price(S, K, T, r, sigma, cp):\n",
    "    d1 = (np.log(S/K) + (r + 0.5*sigma*sigma)*T)/(sigma*np.sqrt(T))\n",
    "    d2 = d1 - sigma*np.sqrt(T)\n",
    "    return (S*norm.cdf(d1) - K*np.exp(-r*T)*norm.cdf(d2)) if cp.upper()==\"C\" else (K*np.exp(-r*T)*norm.cdf(-d2) - S*norm.cdf(-d1))\n",
    "\n",
    "def realized_vol_from_close(close):\n",
    "    ret = np.log(close/close.shift(1)).dropna()\n",
    "    return ret.rolling(21).std()*np.sqrt(252)\n",
    "\n",
    "def get_riskfree_series(start_yyyymmdd, end_yyyymmdd, ticker=\"USGG3M Index\"):\n",
    "    rf = get_bdh_equity(ticker, start_yyyymmdd, end_yyyymmdd, fields=(\"PX_LAST\",))\n",
    "    rf = rf.rename(columns={\"PX_LAST\": \"RF_YLD_PCT\"})\n",
    "    rf[\"rf_daily\"] = (rf[\"RF_YLD_PCT\"]/100.0)/365.0\n",
    "    return rf[[\"rf_daily\"]]\n",
    "\n",
    "# -------------------- The backtest --------------------\n",
    "def backtest_parity(\n",
    "    underlying=\"AAPL US Equity\",\n",
    "    start=\"20240101\",\n",
    "    end  =\"20250918\",\n",
    "    min_dte=25, max_dte=45,\n",
    "    gap_threshold=0.10,\n",
    "    max_hold_days=60,\n",
    "    riskfree_ticker=\"USGG3M Index\"  # for BRL, try \"BZSELIC Index\" if available on your terminal\n",
    "):\n",
    "    px = get_bdh_equity(underlying, start, end, fields=(\"PX_LAST\",))\n",
    "    rf = get_riskfree_series(start, end, ticker=riskfree_ticker)\n",
    "    df = px.join(rf, how=\"left\").fillna(method=\"ffill\")\n",
    "    df[\"rv_21\"] = realized_vol_from_close(df[\"PX_LAST\"])\n",
    "\n",
    "    trades, equity_curve = [], []\n",
    "    open_pos = None\n",
    "\n",
    "    for dt, row in df.iterrows():\n",
    "        S = row[\"PX_LAST\"]\n",
    "        rf_day = float(row[\"rf_daily\"]) if pd.notna(row.get(\"rf_daily\", np.nan)) else 0.0\n",
    "\n",
    "        if open_pos:\n",
    "            open_pos[\"days_held\"] += 1\n",
    "            open_pos[\"cash\"] *= (1.0 + rf_day)\n",
    "            equity_curve.append({\"date\": dt, \"equity\": open_pos[\"equity_mark\"]})\n",
    "        else:\n",
    "            equity_curve.append({\"date\": dt, \"equity\": 0.0})\n",
    "\n",
    "        if open_pos:\n",
    "            if dt >= open_pos[\"expiry\"] or open_pos[\"days_held\"] >= max_hold_days:\n",
    "                pnl = open_pos[\"gap_signed\"]  # simple convergence realization\n",
    "                trades.append({**open_pos, \"exit_date\": dt, \"pnl\": pnl})\n",
    "                open_pos = None\n",
    "            continue\n",
    "\n",
    "        chain = get_chain_for_day(underlying, S, dt, min_dte, max_dte)\n",
    "        if chain.empty:\n",
    "            continue\n",
    "\n",
    "        K    = chain[\"K\"].iloc[0]\n",
    "        Cmid = chain[\"C_mid\"].iloc[0]\n",
    "        Pmid = chain[\"P_mid\"].iloc[0]\n",
    "        expiry = chain[\"expiry\"].iloc[0]\n",
    "        dte   = int(chain[\"DTE\"].iloc[0])\n",
    "        T     = dte/365.0\n",
    "\n",
    "        r_ann = df.loc[:dt].tail(1)[\"rf_daily\"].iloc[0]*365.0 if \"rf_daily\" in df.columns else 0.0\n",
    "        dfac  = np.exp(-r_ann*T)\n",
    "        gap   = (Cmid - Pmid) - (S - K*dfac)\n",
    "\n",
    "        if abs(gap) < gap_threshold:\n",
    "            continue\n",
    "\n",
    "        direction = \"short_call_long_put_shortS_longB\" if gap > 0 else \"long_call_short_put_longS_shortB\"\n",
    "        open_pos = {\n",
    "            \"entry_date\": dt, \"expiry\": expiry, \"days_held\": 0,\n",
    "            \"underlying\": underlying,\n",
    "            \"S0\": S, \"K\": K, \"C_mid0\": Cmid, \"P_mid0\": Pmid,\n",
    "            \"r_ann\": r_ann, \"T\": T, \"dte\": dte,\n",
    "            \"gap\": float(gap), \"gap_signed\": float(np.sign(gap)*abs(gap)),\n",
    "            \"direction\": direction,\n",
    "            \"cash\": K*dfac if gap>0 else -K*dfac,\n",
    "            \"equity_mark\": float(np.sign(gap)*abs(gap))\n",
    "        }\n",
    "\n",
    "    eq = pd.DataFrame(equity_curve).set_index(\"date\")\n",
    "    tr = pd.DataFrame(trades)\n",
    "\n",
    "    if not tr.empty:\n",
    "        total_pnl = tr[\"pnl\"].sum()\n",
    "        hitrate   = (tr[\"pnl\"]>0).mean()\n",
    "        avg_hold  = tr[\"days_held\"].mean()\n",
    "    else:\n",
    "        total_pnl = 0.0; hitrate = np.nan; avg_hold = np.nan\n",
    "\n",
    "    return {\n",
    "        \"underlying_history\": df,\n",
    "        \"equity_curve\": eq,\n",
    "        \"trades\": tr,\n",
    "        \"summary\": {\n",
    "            \"total_pnl_units\": float(total_pnl),\n",
    "            \"num_trades\": int(len(tr)),\n",
    "            \"hit_ratio\": float(hitrate) if pd.notna(hitrate) else None,\n",
    "            \"avg_hold_days\": float(avg_hold) if pd.notna(avg_hold) else None\n",
    "        }\n",
    "    }\n",
    "\n",
    "# -------------------- Plot helper (saves PNG) --------------------\n",
    "def plot_backtest(res, title=\"Parity Arbitrage Backtest\", outfile=None):\n",
    "    uh = res[\"underlying_history\"].copy()\n",
    "    tr = res[\"trades\"].copy() if not res[\"trades\"].empty else pd.DataFrame(columns=[\"exit_date\",\"pnl\"])\n",
    "    daily = pd.Series(0.0, index=uh.index)\n",
    "    if not tr.empty:\n",
    "        tr = tr.set_index(\"exit_date\").sort_index()\n",
    "        for dt, row in tr.iterrows():\n",
    "            if dt in daily.index:\n",
    "                daily.loc[dt] += float(row[\"pnl\"])\n",
    "    cum_pnl = daily.cumsum()\n",
    "    if outfile is None:\n",
    "        outfile = Path(f\"./backtest_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\")\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(cum_pnl.index, cum_pnl.values, linewidth=2)\n",
    "    plt.title(title); plt.xlabel(\"Date\"); plt.ylabel(\"Cumulative Realized PnL (units)\")\n",
    "    plt.grid(True, linewidth=0.5, alpha=0.6); plt.tight_layout()\n",
    "    plt.savefig(outfile, dpi=200); plt.close()\n",
    "    print(\"Saved chart to:\", outfile)\n",
    "\n",
    "# -------------------- Example run (edit ticker/dates and run the cell) --------------------\n",
    "underlying = \"VALE3 BZ Equity\"   # e.g., \"PETR4 BZ Equity\", \"ITUB4 BZ Equity\", \"AAPL US Equity\"\n",
    "start      = \"20240101\"\n",
    "end        = datetime.today().strftime(\"%Y%m%d\")\n",
    "min_dte, max_dte = 25, 45\n",
    "gap_threshold    = 0.10\n",
    "\n",
    "res = backtest_parity(\n",
    "    underlying=underlying,\n",
    "    start=start,\n",
    "    end=end,\n",
    "    min_dte=min_dte,\n",
    "    max_dte=max_dte,\n",
    "    gap_threshold=gap_threshold,\n",
    "    riskfree_ticker=\"BZSELIC Index\"  # BRL proxy; or \"USGG3M Index\"\n",
    ")\n",
    "print(\"Summary:\", res[\"summary\"])\n",
    "print(\"\\nFirst trades:\\n\", res[\"trades\"].head())\n",
    "\n",
    "outfile = f\"{underlying.replace(' ','_')}_parity_backtest.png\"\n",
    "plot_backtest(res, title=f\"{underlying} Parity Arbitrage Backtest\", outfile=outfile)\n",
    "print(f\"Chart saved to: {outfile}\")\n",
    "# ==============================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36e3d215-98f5-480f-aa0d-4d1192f6bfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antoniovd\\AppData\\Local\\Temp\\ipykernel_26964\\1702782002.py:97: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[f] = pd.to_numeric(df[f], errors=\"ignore\")\n",
      "C:\\Users\\antoniovd\\AppData\\Local\\Temp\\ipykernel_26964\\1702782002.py:242: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = px.join(rf, how=\"left\").fillna(method=\"ffill\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: {'total_pnl_units': 0.0, 'num_trades': 0, 'hit_ratio': None, 'avg_hold_days': None}\n",
      "\n",
      "First trades:\n",
      " Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Saved chart to: VALE3_BZ_Equity_fasttest.png\n",
      "Chart saved to: VALE3_BZ_Equity_fasttest.png\n"
     ]
    }
   ],
   "source": [
    "# âš¡ FAST TEST (short window, wider filters)\n",
    "underlying = \"VALE3 BZ Equity\"      # or any other like \"PETR4 BZ Equity\"\n",
    "start      = \"20240701\"              # ~2.5 months back\n",
    "end        = \"20240815\"              # ~6 weeks range â†’ runs very fast\n",
    "\n",
    "min_dte    = 10                       # allow shorter-dated options\n",
    "max_dte    = 60                       # also allow slightly longer ones\n",
    "gap_threshold = 0.05                  # easier to trigger trades\n",
    "\n",
    "res = backtest_parity(\n",
    "    underlying=underlying,\n",
    "    start=start,\n",
    "    end=end,\n",
    "    min_dte=min_dte,\n",
    "    max_dte=max_dte,\n",
    "    gap_threshold=gap_threshold,\n",
    "    riskfree_ticker=\"BZSELIC Index\"\n",
    ")\n",
    "\n",
    "print(\"Summary:\", res[\"summary\"])\n",
    "print(\"\\nFirst trades:\\n\", res[\"trades\"].head())\n",
    "\n",
    "outfile = f\"{underlying.replace(' ','_')}_fasttest.png\"\n",
    "plot_backtest(res, title=f\"{underlying} Parity Arbitrage Backtest (Fast Test)\", outfile=outfile)\n",
    "print(\"Chart saved to:\", outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d854aa3f-6c27-474a-8187-966e485c54f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antoniovd\\AppData\\Local\\Temp\\ipykernel_26964\\3051114834.py:76: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  for f in fields: df[f] = pd.to_numeric(df[f], errors=\"ignore\")\n",
      "C:\\Users\\antoniovd\\AppData\\Local\\Temp\\ipykernel_26964\\3051114834.py:171: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = px.join(rf, how=\"left\").fillna(method=\"ffill\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-01] No options found (S=38.00)\n",
      "[2024-07-15] No options found (S=38.00)\n",
      "[2024-07-29] No options found (S=36.00)\n",
      "[2024-08-12] No options found (S=37.00)\n",
      "Summary: {'total_pnl_units': 0.0, 'num_trades': 0, 'hit_ratio': None, 'avg_hold_days': None}\n",
      "\n",
      "First trades:\n",
      " Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Saved chart to: VALE3_fasttest.png\n",
      "Chart: VALE3_fasttest.png\n"
     ]
    }
   ],
   "source": [
    "# ======================= FAST BACKTEST (persistent session, caching, sampling, progress) =======================\n",
    "import blpapi, pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------- Bloomberg session (persistent) --------------------\n",
    "class BBGSession:\n",
    "    def __init__(self, host=\"localhost\", port=8194):\n",
    "        self.host, self.port = host, port\n",
    "        self.session = None\n",
    "        self.ref = None\n",
    "    def __enter__(self):\n",
    "        so = blpapi.SessionOptions()\n",
    "        so.setServerHost(self.host); so.setServerPort(self.port)\n",
    "        self.session = blpapi.Session(so)\n",
    "        if not self.session.start(): raise RuntimeError(\"Failed to start session.\")\n",
    "        if not self.session.openService(\"//blp/refdata\"): raise RuntimeError(\"Failed to open //blp/refdata.\")\n",
    "        self.ref = self.session.getService(\"//blp/refdata\")\n",
    "        return self\n",
    "    def __exit__(self, exc_type, exc, tb):\n",
    "        if self.session: self.session.stop()\n",
    "\n",
    "def _send_req(session, req, timeout_ms=120_000):\n",
    "    session.sendRequest(req)\n",
    "    msgs = []\n",
    "    while True:\n",
    "        ev = session.nextEvent(timeout_ms)\n",
    "        for m in ev: msgs.append(m)\n",
    "        if ev.eventType() == blpapi.Event.RESPONSE:\n",
    "            break\n",
    "    return msgs\n",
    "\n",
    "def _blp_get(parent_el: blpapi.Element, field_name: str):\n",
    "    if not parent_el.hasElement(field_name): return np.nan\n",
    "    sub = parent_el.getElement(field_name)\n",
    "    for meth in (\"getValueAsFloat64\",\"getValueAsInt64\",\"getValueAsInteger\"):\n",
    "        try: return getattr(sub, meth)()\n",
    "        except Exception: pass\n",
    "    for meth in (\"getValueAsBool\",\"getValueAsDatetime\",\"getValueAsString\"):\n",
    "        try:\n",
    "            val = getattr(sub, meth)()\n",
    "            if isinstance(val, blpapi.Datetime):\n",
    "                return pd.to_datetime(val.strftime(\"%Y-%m-%d\"))\n",
    "            return val\n",
    "        except Exception: pass\n",
    "    try: return sub.getValue()\n",
    "    except Exception: return np.nan\n",
    "\n",
    "# -------------------- Data pulls (reuse same session) --------------------\n",
    "def get_bdh_equity(bbg: BBGSession, symbol, start_yyyymmdd, end_yyyymmdd, fields=(\"PX_LAST\",), periodicity=\"DAILY\"):\n",
    "    r = bbg.ref.createRequest(\"HistoricalDataRequest\")\n",
    "    r.getElement(\"securities\").appendValue(symbol)\n",
    "    fe = r.getElement(\"fields\")\n",
    "    for f in fields: fe.appendValue(f)\n",
    "    r.set(\"startDate\", start_yyyymmdd); r.set(\"endDate\", end_yyyymmdd)\n",
    "    r.set(\"periodicitySelection\", periodicity)\n",
    "    msgs = _send_req(bbg.session, r)\n",
    "\n",
    "    rows = []\n",
    "    for msg in msgs:\n",
    "        if not msg.hasElement(\"securityData\"): continue\n",
    "        sd = msg.getElement(\"securityData\")\n",
    "        if not sd.hasElement(\"fieldData\"): continue\n",
    "        fd = sd.getElement(\"fieldData\")\n",
    "        for i in range(fd.numValues()):\n",
    "            row_el = fd.getValueAsElement(i)\n",
    "            d = row_el.getElementAsDatetime(\"date\")\n",
    "            out = {\"date\": pd.to_datetime(d.strftime(\"%Y-%m-%d\"))}\n",
    "            for f in fields: out[f] = _blp_get(row_el, f)\n",
    "            rows.append(out)\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(columns=list(fields)).astype(float)\n",
    "    df = df.sort_values(\"date\").set_index(\"date\")\n",
    "    for f in fields: df[f] = pd.to_numeric(df[f], errors=\"ignore\")\n",
    "    return df\n",
    "\n",
    "def get_riskfree_series(bbg: BBGSession, start_yyyymmdd, end_yyyymmdd, ticker=\"USGG3M Index\"):\n",
    "    rf = get_bdh_equity(bbg, ticker, start_yyyymmdd, end_yyyymmdd, fields=(\"PX_LAST\",))\n",
    "    rf = rf.rename(columns={\"PX_LAST\":\"RF_YLD_PCT\"})\n",
    "    rf[\"rf_daily\"] = (rf[\"RF_YLD_PCT\"]/100.0)/365.0\n",
    "    return rf[[\"rf_daily\"]]\n",
    "\n",
    "def _parse_bdp_messages_to_df(msgs, fields):\n",
    "    rows = []\n",
    "    for msg in msgs:\n",
    "        if not msg.hasElement(\"securityData\"): continue\n",
    "        sdata = msg.getElement(\"securityData\")\n",
    "        for i in range(sdata.numValues()):\n",
    "            e = sdata.getValueAsElement(i)\n",
    "            sec = e.getElementAsString(\"security\")\n",
    "            if not e.hasElement(\"fieldData\"): continue\n",
    "            fdata = e.getElement(\"fieldData\")\n",
    "            row = {\"security\": sec}\n",
    "            for f in fields: row[f] = _blp_get(fdata, f)\n",
    "            rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Cache: (expiry_str -> list of option tickers) within a short TTL window\n",
    "class ChainCache:\n",
    "    def __init__(self): self.store = {}\n",
    "    def get(self, key): return self.store.get(key)\n",
    "    def put(self, key, val): self.store[key] = val\n",
    "\n",
    "def get_chain_snapshot(bbg: BBGSession, underlying, expiry_yyyymmdd, max_points=600, chain_cache: ChainCache|None=None):\n",
    "    cache_key = (underlying, expiry_yyyymmdd, max_points)\n",
    "    if chain_cache:\n",
    "        cached = chain_cache.get(cache_key)\n",
    "        if cached is not None:\n",
    "            return cached[:]  # copy\n",
    "\n",
    "    # BDS: CHAIN_TICKERS\n",
    "    bds = bbg.ref.createRequest(\"ReferenceDataRequest\")\n",
    "    bds.getElement(\"securities\").appendValue(underlying)\n",
    "    bds.getElement(\"fields\").appendValue(\"CHAIN_TICKERS\")\n",
    "    ov = bds.getElement(\"overrides\")\n",
    "    o1 = ov.appendElement(); o1.setElement(\"fieldId\",\"CHAIN_EXP_DT_OVRD\");   o1.setElement(\"value\",expiry_yyyymmdd)\n",
    "    o2 = ov.appendElement(); o2.setElement(\"fieldId\",\"CHAIN_POINTS_LIMIT\"); o2.setElement(\"value\",str(max_points))\n",
    "    msgs = _send_req(bbg.session, bds)\n",
    "\n",
    "    tickers = []\n",
    "    for msg in msgs:\n",
    "        if not msg.hasElement(\"securityData\"): continue\n",
    "        arr = msg.getElement(\"securityData\")\n",
    "        for i in range(arr.numValues()):\n",
    "            sd = arr.getValueAsElement(i)\n",
    "            if not sd.hasElement(\"fieldData\"): continue\n",
    "            fdata = sd.getElement(\"fieldData\")\n",
    "            if not fdata.hasElement(\"CHAIN_TICKERS\"): continue\n",
    "            bulk = fdata.getElement(\"CHAIN_TICKERS\")\n",
    "            for j in range(bulk.numValues()):\n",
    "                e = bulk.getValueAsElement(j)\n",
    "                if e.hasElement(\"Ticker\"):\n",
    "                    tickers.append(e.getElementAsString(\"Ticker\"))\n",
    "\n",
    "    if chain_cache:\n",
    "        chain_cache.put(cache_key, tickers)\n",
    "    return tickers\n",
    "\n",
    "def get_option_fields(bbg: BBGSession, option_tickers, fields):\n",
    "    if not option_tickers: return pd.DataFrame()\n",
    "    bdp = bbg.ref.createRequest(\"ReferenceDataRequest\")\n",
    "    se = bdp.getElement(\"securities\"); [se.appendValue(t) for t in option_tickers]\n",
    "    fe = bdp.getElement(\"fields\");     [fe.appendValue(f) for f in fields]\n",
    "    msgs2 = _send_req(bbg.session, bdp)\n",
    "    df = _parse_bdp_messages_to_df(msgs2, fields)\n",
    "    return df\n",
    "\n",
    "# -------------------- Quant helpers --------------------\n",
    "def realized_vol_from_close(close):\n",
    "    ret = np.log(close/close.shift(1)).dropna()\n",
    "    return ret.rolling(21).std()*np.sqrt(252)\n",
    "\n",
    "# -------------------- Faster backtest --------------------\n",
    "def backtest_parity_fast(\n",
    "    underlying=\"VALE3 BZ Equity\",\n",
    "    start=\"20240701\",\n",
    "    end  =\"20240815\",\n",
    "    min_dte=10, max_dte=60,\n",
    "    gap_threshold=0.05,\n",
    "    riskfree_ticker=\"BZSELIC Index\",\n",
    "    step_days=2,                  # <â€” sample every N days for speed\n",
    "    probe_offsets=(-14,-7,0,7,14),# <â€” fewer expiry probes around ~1 month\n",
    "    max_points=400,               # <â€” smaller chain size\n",
    "    progress_every=5              # print progress every N iterations\n",
    "):\n",
    "    with BBGSession() as bbg:\n",
    "        px = get_bdh_equity(bbg, underlying, start, end, fields=(\"PX_LAST\",))\n",
    "        rf = get_riskfree_series(bbg, start, end, ticker=riskfree_ticker)\n",
    "        df = px.join(rf, how=\"left\").fillna(method=\"ffill\")\n",
    "        df[\"rv_21\"] = realized_vol_from_close(df[\"PX_LAST\"])\n",
    "\n",
    "        dates = df.index.to_list()\n",
    "        trades, equity_curve = [], []\n",
    "        open_pos = None\n",
    "        chain_cache = ChainCache()\n",
    "\n",
    "        for idx, dt in enumerate(dates):\n",
    "            if idx % step_days != 0:\n",
    "                equity_curve.append({\"date\": dt, \"equity\": 0.0 if not open_pos else open_pos[\"equity_mark\"]})\n",
    "                continue\n",
    "\n",
    "            S = float(df.loc[dt, \"PX_LAST\"])\n",
    "            rf_day = float(df.loc[dt, \"rf_daily\"]) if \"rf_daily\" in df.columns and pd.notna(df.loc[dt, \"rf_daily\"]) else 0.0\n",
    "\n",
    "            if open_pos:\n",
    "                open_pos[\"days_held\"] += step_days\n",
    "                open_pos[\"cash\"] *= (1.0 + rf_day)**step_days\n",
    "                equity_curve.append({\"date\": dt, \"equity\": open_pos[\"equity_mark\"]})\n",
    "            else:\n",
    "                equity_curve.append({\"date\": dt, \"equity\": 0.0})\n",
    "\n",
    "            if open_pos:\n",
    "                if dt >= open_pos[\"expiry\"]:\n",
    "                    pnl = open_pos[\"gap_signed\"]\n",
    "                    trades.append({**open_pos, \"exit_date\": dt, \"pnl\": pnl})\n",
    "                    open_pos = None\n",
    "                continue\n",
    "\n",
    "            # expiry candidates near ~1 month from dt\n",
    "            base = dt + timedelta(days=(min_dte+max_dte)//2)\n",
    "            expiries = [(base + timedelta(days=o)).strftime(\"%Y%m%d\") for o in probe_offsets]\n",
    "\n",
    "            picked = None\n",
    "            fields = [\"PX_BID\",\"PX_ASK\",\"IMPLIED_VOLATILITY\",\n",
    "                      \"DELTA\",\"GAMMA\",\"THETA\",\"VEGA\",\n",
    "                      \"OPT_STRIKE_PX\",\"OPT_EXPIRE_DT\",\"OPT_PUT_CALL\",\"OPT_UNDL_PX\"]\n",
    "\n",
    "            for exp in expiries:\n",
    "                tickers = get_chain_snapshot(bbg, underlying, exp, max_points=max_points, chain_cache=chain_cache)\n",
    "                if not tickers: continue\n",
    "                dfopt = get_option_fields(bbg, tickers, fields)\n",
    "                if dfopt.empty: continue\n",
    "\n",
    "                dfopt[\"OPT_EXPIRE_DT\"] = pd.to_datetime(dfopt[\"OPT_EXPIRE_DT\"], errors=\"coerce\")\n",
    "                dfopt[\"OPT_STRIKE_PX\"] = pd.to_numeric(dfopt[\"OPT_STRIKE_PX\"], errors=\"coerce\")\n",
    "                dfopt[\"OPT_PUT_CALL\"]  = dfopt[\"OPT_PUT_CALL\"].astype(str).str.upper()\n",
    "                dfopt[\"PX_BID\"] = pd.to_numeric(dfopt[\"PX_BID\"], errors=\"coerce\")\n",
    "                dfopt[\"PX_ASK\"] = pd.to_numeric(dfopt[\"PX_ASK\"], errors=\"coerce\")\n",
    "                dfopt[\"MID\"]    = (dfopt[\"PX_BID\"] + dfopt[\"PX_ASK\"])/2.0\n",
    "\n",
    "                dfopt[\"DTE\"] = (dfopt[\"OPT_EXPIRE_DT\"] - pd.Timestamp(dt)).dt.days\n",
    "                dfopt = dfopt[(dfopt[\"DTE\"]>=min_dte) & (dfopt[\"DTE\"]<=max_dte)].dropna(subset=[\"MID\",\"OPT_STRIKE_PX\",\"OPT_EXPIRE_DT\"])\n",
    "                if dfopt.empty: continue\n",
    "\n",
    "                dfopt[\"atm_dist\"] = (dfopt[\"OPT_STRIKE_PX\"] - S).abs()\n",
    "                atmC = dfopt[dfopt[\"OPT_PUT_CALL\"]==\"C\"].sort_values([\"atm_dist\",\"DTE\"]).groupby(\"OPT_EXPIRE_DT\").head(1)\n",
    "                atmP = dfopt[dfopt[\"OPT_PUT_CALL\"]==\"P\"].sort_values([\"atm_dist\",\"DTE\"]).groupby(\"OPT_EXPIRE_DT\").head(1)\n",
    "                if atmC.empty or atmP.empty: continue\n",
    "                pair = atmC.merge(atmP, on=\"OPT_EXPIRE_DT\", suffixes=(\"_C\",\"_P\"))\n",
    "                if pair.empty: continue\n",
    "                pair[\"combo_dist\"] = pair[\"atm_dist_C\"] + pair[\"atm_dist_P\"]\n",
    "                picked = pair.sort_values([\"combo_dist\",\"DTE_C\"]).head(1)\n",
    "                if not picked.empty: break\n",
    "\n",
    "            if picked is None or picked.empty:\n",
    "                if idx % progress_every == 0:\n",
    "                    print(f\"[{dt.date()}] No options found (S={S:.2f})\")\n",
    "                continue\n",
    "\n",
    "            K    = float(picked[\"OPT_STRIKE_PX_C\"].iloc[0])\n",
    "            Cmid = float(picked[\"MID_C\"].iloc[0])\n",
    "            Pmid = float(picked[\"MID_P\"].iloc[0])\n",
    "            expiry = picked[\"OPT_EXPIRE_DT\"].iloc[0]\n",
    "            dte    = int(picked[\"DTE_C\"].iloc[0])\n",
    "            T      = dte/365.0\n",
    "\n",
    "            r_ann = (df.loc[dt, \"rf_daily\"]*365.0) if \"rf_daily\" in df.columns and pd.notna(df.loc[dt, \"rf_daily\"]) else 0.0\n",
    "            dfac  = np.exp(-r_ann*T)\n",
    "            gap   = (Cmid - Pmid) - (S - K*dfac)\n",
    "\n",
    "            if abs(gap) < gap_threshold:\n",
    "                if idx % progress_every == 0:\n",
    "                    print(f\"[{dt.date()}] Gap {gap:.3f} < thr {gap_threshold}\")\n",
    "                continue\n",
    "\n",
    "            direction = \"short_call_long_put_shortS_longB\" if gap > 0 else \"long_call_short_put_longS_shortB\"\n",
    "            open_pos = {\n",
    "                \"entry_date\": dt, \"expiry\": expiry, \"days_held\": 0,\n",
    "                \"underlying\": underlying,\n",
    "                \"S0\": S, \"K\": K, \"C_mid0\": Cmid, \"P_mid0\": Pmid,\n",
    "                \"r_ann\": r_ann, \"T\": T, \"dte\": dte,\n",
    "                \"gap\": float(gap), \"gap_signed\": float(np.sign(gap)*abs(gap)),\n",
    "                \"direction\": direction,\n",
    "                \"cash\": K*dfac if gap>0 else -K*dfac,\n",
    "                \"equity_mark\": float(np.sign(gap)*abs(gap))\n",
    "            }\n",
    "\n",
    "            if idx % progress_every == 0:\n",
    "                print(f\"[{dt.date()}] ENTER {direction} | DTE={dte} K={K:.2f} S={S:.2f} gap={gap:.3f}\")\n",
    "\n",
    "        eq = pd.DataFrame(equity_curve).set_index(\"date\")\n",
    "        tr = pd.DataFrame(trades)\n",
    "        if not tr.empty:\n",
    "            total_pnl = tr[\"pnl\"].sum()\n",
    "            hitrate   = (tr[\"pnl\"]>0).mean()\n",
    "            avg_hold  = tr[\"days_held\"].mean()\n",
    "        else:\n",
    "            total_pnl = 0.0; hitrate = np.nan; avg_hold = np.nan\n",
    "\n",
    "        return {\n",
    "            \"underlying_history\": df,\n",
    "            \"equity_curve\": eq,\n",
    "            \"trades\": tr,\n",
    "            \"summary\": {\n",
    "                \"total_pnl_units\": float(total_pnl),\n",
    "                \"num_trades\": int(len(tr)),\n",
    "                \"hit_ratio\": float(hitrate) if pd.notna(hitrate) else None,\n",
    "                \"avg_hold_days\": float(avg_hold) if pd.notna(avg_hold) else None\n",
    "            }\n",
    "        }\n",
    "\n",
    "# -------------------- Plot helper (same as before) --------------------\n",
    "def plot_backtest(res, title=\"Parity Arbitrage Backtest\", outfile=None):\n",
    "    uh = res[\"underlying_history\"].copy()\n",
    "    tr = res[\"trades\"].copy() if not res[\"trades\"].empty else pd.DataFrame(columns=[\"exit_date\",\"pnl\"])\n",
    "    daily = pd.Series(0.0, index=uh.index)\n",
    "    if not tr.empty:\n",
    "        tr = tr.set_index(\"exit_date\").sort_index()\n",
    "        for dt, row in tr.iterrows():\n",
    "            if dt in daily.index:\n",
    "                daily.loc[dt] += float(row[\"pnl\"])\n",
    "    cum_pnl = daily.cumsum()\n",
    "    if outfile is None:\n",
    "        outfile = Path(f\"./backtest_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\")\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(cum_pnl.index, cum_pnl.values, linewidth=2)\n",
    "    plt.title(title); plt.xlabel(\"Date\"); plt.ylabel(\"Cumulative Realized PnL (units)\")\n",
    "    plt.grid(True, linewidth=0.5, alpha=0.6); plt.tight_layout()\n",
    "    plt.savefig(outfile, dpi=200); plt.close()\n",
    "    print(\"Saved chart to:\", outfile)\n",
    "\n",
    "# -------------------- FAST RUN EXAMPLE --------------------\n",
    "res = backtest_parity_fast(\n",
    "    underlying=\"PETR4 BZ Equity\",\n",
    "    start=\"20240701\",\n",
    "    end=\"20240815\",\n",
    "    min_dte=10, max_dte=60,\n",
    "    gap_threshold=0.05,\n",
    "    riskfree_ticker=\"BZSELIC Index\",\n",
    "    step_days=2,           # sample every 2 days\n",
    "    probe_offsets=(-7,0,7) # fewer expiry probes for speed\n",
    ")\n",
    "print(\"Summary:\", res[\"summary\"])\n",
    "print(\"\\nFirst trades:\\n\", res[\"trades\"].head())\n",
    "\n",
    "outfile = \"VALE3_fasttest.png\"\n",
    "plot_backtest(res, title=\"VALE3 Parity Arbitrage Backtest (Fast)\", outfile=outfile)\n",
    "print(\"Chart:\", outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7d9e33c-4208-4f8c-b4a8-17dbfe02dbb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "backtest_parity_fast() got an unexpected keyword argument 'fast'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mbacktest_parity_fast\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43munderlying\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAAPL US Equity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m20240701\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m20240815\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_dte\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_dte\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgap_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mriskfree_ticker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUSGG3M Index\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep_days\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobe_offsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: backtest_parity_fast() got an unexpected keyword argument 'fast'"
     ]
    }
   ],
   "source": [
    "res = backtest_parity_fast(\n",
    "    underlying=\"AAPL US Equity\",\n",
    "    start=\"20240701\", end=\"20240815\",\n",
    "    fast=True, min_dte=10, max_dte=60, gap_threshold=0.05,\n",
    "    riskfree_ticker=\"USGG3M Index\",\n",
    "    step_days=2, probe_offsets=(-7,0,7)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cb034915-4659-4128-afe6-7ec8f3178c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antoniovd\\AppData\\Local\\Temp\\ipykernel_26964\\137042505.py:83: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[f] = pd.to_numeric(df[f], errors=\"ignore\")\n",
      "C:\\Users\\antoniovd\\AppData\\Local\\Temp\\ipykernel_26964\\137042505.py:349: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = px.join(rf, how=\"left\").fillna(method=\"ffill\")\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_chain_for_day() got an unexpected keyword argument 'max_points'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 470\u001b[0m\n\u001b[0;32m    468\u001b[0m min_dte, max_dte \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m60\u001b[39m           \u001b[38;5;66;03m# wider window helps on B3\u001b[39;00m\n\u001b[0;32m    469\u001b[0m gap_threshold    \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m\n\u001b[1;32m--> 470\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mbacktest_parity\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m    \u001b[49m\u001b[43munderlying\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munderlying\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_dte\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_dte\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_dte\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_dte\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgap_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgap_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mriskfree_ticker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBZSELIC Index\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep_days\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                     \u001b[49m\u001b[38;5;66;43;03m# sample every 2 business days for speed\u001b[39;49;00m\n\u001b[0;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m                 \u001b[49m\u001b[38;5;66;43;03m# print heartbeat\u001b[39;49;00m\n\u001b[0;32m    480\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummary:\u001b[39m\u001b[38;5;124m\"\u001b[39m, res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    482\u001b[0m outfile \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00munderlying\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_parity_backtest.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[44], line 381\u001b[0m, in \u001b[0;36mbacktest_parity\u001b[1;34m(underlying, start, end, min_dte, max_dte, gap_threshold, max_hold_days, riskfree_ticker, step_days, progress_every)\u001b[0m\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# chain lookup (now with built-in fallback)\u001b[39;00m\n\u001b[1;32m--> 381\u001b[0m chain \u001b[38;5;241m=\u001b[39m \u001b[43mget_chain_for_day\u001b[49m\u001b[43m(\u001b[49m\u001b[43munderlying\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_dte\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_dte\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chain\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m progress_every \u001b[38;5;129;01mand\u001b[39;00m idx \u001b[38;5;241m%\u001b[39m progress_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: get_chain_for_day() got an unexpected keyword argument 'max_points'"
     ]
    }
   ],
   "source": [
    "# ======================= ALL-IN-ONE (KEEPS ORIGINAL API, WITH ROBUST FALLBACKS) =======================\n",
    "# Works on a Bloomberg Terminal PC (Desktop API; localhost:8194)\n",
    "# Public functions (same names/signatures as before):\n",
    "#   get_bdh_equity, get_chain_for_day, backtest_parity, plot_backtest\n",
    "\n",
    "import blpapi, pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------- Bloomberg session helpers --------------------\n",
    "def _start_bbg_session(host=\"localhost\", port=8194):\n",
    "    so = blpapi.SessionOptions()\n",
    "    so.setServerHost(host); so.setServerPort(port)\n",
    "    s = blpapi.Session(so)\n",
    "    if not s.start(): raise RuntimeError(\"Failed to start Bloomberg session.\")\n",
    "    if not s.openService(\"//blp/refdata\"): raise RuntimeError(\"Failed to open //blp/refdata.\")\n",
    "    return s, s.getService(\"//blp/refdata\")\n",
    "\n",
    "def _send_req(session, req, timeout_ms=120_000):\n",
    "    session.sendRequest(req)\n",
    "    msgs = []\n",
    "    while True:\n",
    "        ev = session.nextEvent(timeout_ms)\n",
    "        for m in ev: msgs.append(m)\n",
    "        if ev.eventType() == blpapi.Event.RESPONSE:\n",
    "            break\n",
    "    return msgs\n",
    "\n",
    "# -------------------- Safe extractor for blpapi.Element --------------------\n",
    "def _blp_get(parent_el: blpapi.Element, field_name: str):\n",
    "    if not parent_el.hasElement(field_name):\n",
    "        return np.nan\n",
    "    sub = parent_el.getElement(field_name)\n",
    "    # numeric\n",
    "    for meth in (\"getValueAsFloat64\",\"getValueAsInt64\",\"getValueAsInteger\"):\n",
    "        try: return getattr(sub, meth)()\n",
    "        except Exception: pass\n",
    "    # other common types\n",
    "    for meth in (\"getValueAsBool\",\"getValueAsDatetime\",\"getValueAsString\"):\n",
    "        try:\n",
    "            val = getattr(sub, meth)()\n",
    "            if isinstance(val, blpapi.Datetime):\n",
    "                return pd.to_datetime(val.strftime(\"%Y-%m-%d\"))\n",
    "            return val\n",
    "        except Exception: pass\n",
    "    # fallback\n",
    "    try: return sub.getValue()\n",
    "    except Exception: return np.nan\n",
    "\n",
    "# -------------------- BDH: historical for any security (e.g., equity, rates) --------------------\n",
    "def get_bdh_equity(symbol_bbg, start_yyyymmdd, end_yyyymmdd, fields=(\"PX_LAST\",), periodicity=\"DAILY\"):\n",
    "    s, ref = _start_bbg_session()\n",
    "    try:\n",
    "        r = ref.createRequest(\"HistoricalDataRequest\")\n",
    "        r.getElement(\"securities\").appendValue(symbol_bbg)\n",
    "        fe = r.getElement(\"fields\")\n",
    "        for f in fields: fe.appendValue(f)\n",
    "        r.set(\"startDate\", start_yyyymmdd)\n",
    "        r.set(\"endDate\", end_yyyymmdd)\n",
    "        r.set(\"periodicitySelection\", periodicity)\n",
    "        msgs = _send_req(s, r)\n",
    "\n",
    "        rows = []\n",
    "        for msg in msgs:\n",
    "            if not msg.hasElement(\"securityData\"): continue\n",
    "            sd = msg.getElement(\"securityData\")\n",
    "            if not sd.hasElement(\"fieldData\"): continue\n",
    "            fd = sd.getElement(\"fieldData\")\n",
    "            for i in range(fd.numValues()):\n",
    "                row_el = fd.getValueAsElement(i)\n",
    "                d = row_el.getElementAsDatetime(\"date\")\n",
    "                out = {\"date\": pd.to_datetime(d.strftime(\"%Y-%m-%d\"))}\n",
    "                for f in fields:\n",
    "                    out[f] = _blp_get(row_el, f)\n",
    "                rows.append(out)\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "        if df.empty:\n",
    "            return pd.DataFrame(columns=list(fields)).astype(float)\n",
    "        df = df.sort_values(\"date\").set_index(\"date\")\n",
    "        for f in fields:\n",
    "            df[f] = pd.to_numeric(df[f], errors=\"ignore\")\n",
    "        return df\n",
    "    finally:\n",
    "        s.stop()\n",
    "\n",
    "def get_riskfree_series(start_yyyymmdd, end_yyyymmdd, ticker=\"USGG3M Index\"):\n",
    "    rf = get_bdh_equity(ticker, start_yyyymmdd, end_yyyymmdd, fields=(\"PX_LAST\",))\n",
    "    rf = rf.rename(columns={\"PX_LAST\":\"RF_YLD_PCT\"})\n",
    "    rf[\"rf_daily\"] = (rf[\"RF_YLD_PCT\"]/100.0)/365.0\n",
    "    return rf[[\"rf_daily\"]]\n",
    "\n",
    "# -------------------- Helper: parse BDP messages to DataFrame --------------------\n",
    "def _parse_bdp_messages_to_df(msgs, fields):\n",
    "    rows = []\n",
    "    for msg in msgs:\n",
    "        if not msg.hasElement(\"securityData\"):\n",
    "            continue\n",
    "        sdata = msg.getElement(\"securityData\")\n",
    "        for i in range(sdata.numValues()):\n",
    "            e = sdata.getValueAsElement(i)\n",
    "            sec = e.getElementAsString(\"security\")\n",
    "            if not e.hasElement(\"fieldData\"):\n",
    "                continue\n",
    "            fdata = e.getElement(\"fieldData\")\n",
    "            row = {\"security\": sec}\n",
    "            for f in fields:\n",
    "                row[f] = _blp_get(fdata, f)\n",
    "            rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# -------------------- Option chain (with robust fallbacks) --------------------\n",
    "# -------------------- Option chain (BDP-based synthetic scan; no CHAIN_TICKERS needed) --------------------\n",
    "def get_chain_for_day(\n",
    "    underlying_bbg,\n",
    "    spot_px,\n",
    "    trade_date,\n",
    "    target_min_dte=25,\n",
    "    target_max_dte=45,\n",
    "    strike_band=0.20,       # Â±20% around spot\n",
    "    strike_step=1.0,        # $1 increments\n",
    "    max_strikes=101,        # safety cap (kept by band/step anyway)\n",
    "    verbose=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Build an options snapshot WITHOUT using CHAIN_TICKERS (works even when chain bulk field isn't entitled).\n",
    "    1) Create expiry candidates (nearest Fridays within DTE window).\n",
    "    2) Build strike ladder around spot.\n",
    "    3) Query BDP in bulk for both Calls and Puts, then pick ATM pair.\n",
    "\n",
    "    Returns a 1-row DataFrame with chosen ATM call/put or empty DF if none.\n",
    "    \"\"\"\n",
    "    # --- helpers ---\n",
    "    def _bbg_base(under):\n",
    "        # \"AAPL US Equity\" -> \"AAPL US\"\n",
    "        parts = under.split()\n",
    "        if len(parts) < 3:\n",
    "            raise ValueError(f\"Unexpected underlying format: {under}\")\n",
    "        return f\"{parts[0]} {parts[1]}\"\n",
    "\n",
    "    def _nearest_friday(d):\n",
    "        # Move to Friday of the same week (or next) depending on day\n",
    "        wd = d.weekday()  # Mon=0 ... Sun=6\n",
    "        if wd <= 4:\n",
    "            return d + timedelta(days=(4 - wd))\n",
    "        else:\n",
    "            # Sat/Sun -> next Friday\n",
    "            return d + timedelta(days=(11 - wd))\n",
    "\n",
    "    def _expiry_candidates(trade_dt, min_dte, max_dte):\n",
    "        # build a small set of Friday expiries (unique) inside [min_dte, max_dte]\n",
    "        exps = set()\n",
    "        for days_ahead in range(min_dte, max_dte + 1, 7):\n",
    "            exp = _nearest_friday(trade_dt + timedelta(days=days_ahead))\n",
    "            exps.add(exp)\n",
    "        # keep a handful (sorted)\n",
    "        exps = sorted(list(exps))\n",
    "        return exps[:8]  # limit to 8 expiries for speed\n",
    "\n",
    "    def _format_bbg_opt(base, exp_dt, cp, strike):\n",
    "        # Bloomberg std: \"<BASE> <MM/DD/YY> C123 Equity\"\n",
    "        # base is \"AAPL US\", cp in {\"C\",\"P\"}, strike as int or rounded price\n",
    "        mmddyy = exp_dt.strftime(\"%m/%d/%y\")\n",
    "        # strikes must be integers if step=1.0; format like 200, 205, etc.\n",
    "        if abs(strike - round(strike)) < 1e-6:\n",
    "            strike_txt = str(int(round(strike)))\n",
    "        else:\n",
    "            strike_txt = f\"{strike:.2f}\".rstrip(\"0\").rstrip(\".\")\n",
    "        return f\"{base} {mmddyy} {cp}{strike_txt} Equity\"\n",
    "\n",
    "    # --- start session ---\n",
    "    s, ref = _start_bbg_session()\n",
    "    try:\n",
    "        base = _bbg_base(underlying_bbg)\n",
    "        trade_dt = pd.Timestamp(trade_date)\n",
    "        exps = _expiry_candidates(trade_dt, target_min_dte, target_max_dte)\n",
    "        if not exps:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # strike ladder around spot\n",
    "        lo = max(0.01, spot_px * (1.0 - strike_band))\n",
    "        hi = spot_px * (1.0 + strike_band)\n",
    "        # ensure step not zero, protect from insane values\n",
    "        step = max(0.01, float(strike_step))\n",
    "        strikes = np.arange(np.floor(lo), np.ceil(hi) + 1e-9, step)\n",
    "        if len(strikes) > max_strikes:\n",
    "            # thin them evenly if extremely dense\n",
    "            idx = np.linspace(0, len(strikes) - 1, max_strikes).round().astype(int)\n",
    "            strikes = strikes[idx]\n",
    "        strikes = np.unique(np.round(strikes, 2))\n",
    "\n",
    "        # Build bulk list of option tickers to request via BDP\n",
    "        sec_list = []\n",
    "        meta = []  # to remember CP/strike/expiry per security\n",
    "        for exp in exps:\n",
    "            for cp in (\"C\", \"P\"):\n",
    "                for K in strikes:\n",
    "                    sec = _format_bbg_opt(base, exp, cp, K)\n",
    "                    sec_list.append(sec)\n",
    "                    meta.append({\"sec\": sec, \"cp\": cp, \"K\": float(K), \"expiry\": exp})\n",
    "\n",
    "        if not sec_list:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # BDP request\n",
    "        fields = [\n",
    "            \"PX_BID\",\"PX_ASK\",\n",
    "            \"OPT_STRIKE_PX\",\"OPT_EXPIRE_DT\",\"OPT_PUT_CALL\",\n",
    "            \"IVOL_MID\",  # preferred\n",
    "            \"IMPLIED_VOLATILITY\"  # fallback (some sources)\n",
    "        ]\n",
    "        bdp = ref.createRequest(\"ReferenceDataRequest\")\n",
    "        se = bdp.getElement(\"securities\")\n",
    "        for sec in sec_list:\n",
    "            se.appendValue(sec)\n",
    "        fe = bdp.getElement(\"fields\")\n",
    "        for f in fields:\n",
    "            fe.appendValue(f)\n",
    "\n",
    "        msgs = _send_req(s, bdp)\n",
    "\n",
    "        # parse\n",
    "        rows = []\n",
    "        meta_map = {m[\"sec\"]: m for m in meta}\n",
    "        for msg in msgs:\n",
    "            if not msg.hasElement(\"securityData\"):\n",
    "                continue\n",
    "            sdata = msg.getElement(\"securityData\")\n",
    "            for i in range(sdata.numValues()):\n",
    "                e = sdata.getValueAsElement(i)\n",
    "                sec = e.getElementAsString(\"security\")\n",
    "                if not e.hasElement(\"fieldData\"):\n",
    "                    continue\n",
    "                fd = e.getElement(\"fieldData\")\n",
    "\n",
    "                def _get(fd, name):\n",
    "                    if not fd.hasElement(name): return np.nan\n",
    "                    sub = fd.getElement(name)\n",
    "                    # try float\n",
    "                    for meth in (\"getValueAsFloat64\",\"getValueAsInt64\",\"getValueAsInteger\"):\n",
    "                        try: return getattr(sub, meth)()\n",
    "                        except Exception: pass\n",
    "                    # then string/datetime\n",
    "                    for meth in (\"getValueAsDatetime\",\"getValueAsString\"):\n",
    "                        try:\n",
    "                            val = getattr(sub, meth)()\n",
    "                            if isinstance(val, blpapi.Datetime):\n",
    "                                return pd.to_datetime(val.strftime(\"%Y-%m-%d\"))\n",
    "                            return val\n",
    "                        except Exception: pass\n",
    "                    try: return sub.getValue()\n",
    "                    except Exception: return np.nan\n",
    "\n",
    "                bid = pd.to_numeric(_get(fd, \"PX_BID\"), errors=\"coerce\")\n",
    "                ask = pd.to_numeric(_get(fd, \"PX_ASK\"), errors=\"coerce\")\n",
    "                if pd.isna(bid) and pd.isna(ask):\n",
    "                    continue  # skip dead securities\n",
    "\n",
    "                Kfd  = _get(fd, \"OPT_STRIKE_PX\")\n",
    "                Efd  = _get(fd, \"OPT_EXPIRE_DT\")\n",
    "                PCfd = _get(fd, \"OPT_PUT_CALL\")\n",
    "                iv1  = _get(fd, \"IVOL_MID\")\n",
    "                iv2  = _get(fd, \"IMPLIED_VOLATILITY\")\n",
    "\n",
    "                m = meta_map.get(sec, None)\n",
    "                K = float(Kfd) if pd.notna(Kfd) else (m[\"K\"] if m else np.nan)\n",
    "                E = pd.to_datetime(Efd) if not isinstance(Efd, pd.Timestamp) else Efd\n",
    "                if pd.isna(E) and m:\n",
    "                    E = m[\"expiry\"]\n",
    "                cp = (str(PCfd).upper() if isinstance(PCfd, str) else (m[\"cp\"] if m else None))\n",
    "\n",
    "                row = {\n",
    "                    \"security\": sec,\n",
    "                    \"OPT_STRIKE_PX\": K,\n",
    "                    \"OPT_EXPIRE_DT\": E,\n",
    "                    \"OPT_PUT_CALL\": cp,\n",
    "                    \"PX_BID\": float(bid) if pd.notna(bid) else np.nan,\n",
    "                    \"PX_ASK\": float(ask) if pd.notna(ask) else np.nan,\n",
    "                    \"MID\": np.nan if (pd.isna(bid) or pd.isna(ask)) else (float(bid)+float(ask))/2.0,\n",
    "                    \"IMPLIED_VOLATILITY\": pd.to_numeric(iv1, errors=\"coerce\") if pd.notna(iv1) else pd.to_numeric(iv2, errors=\"coerce\")\n",
    "                }\n",
    "                rows.append(row)\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "        if df.empty:\n",
    "            if verbose: print(\"[synthetic] No options returned via BDP.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Clean and filter by DTE\n",
    "        df = df.dropna(subset=[\"OPT_STRIKE_PX\",\"OPT_EXPIRE_DT\",\"OPT_PUT_CALL\",\"MID\"])\n",
    "        df[\"OPT_EXPIRE_DT\"] = pd.to_datetime(df[\"OPT_EXPIRE_DT\"], errors=\"coerce\")\n",
    "        df[\"DTE\"] = (df[\"OPT_EXPIRE_DT\"] - trade_dt).dt.days\n",
    "        df = df[(df[\"DTE\"]>=target_min_dte) & (df[\"DTE\"]<=target_max_dte)].copy()\n",
    "        if df.empty:\n",
    "            if verbose: print(\"[synthetic] All candidates filtered out by DTE window.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Pick ATM C & P from each expiry; then best pair overall\n",
    "        df[\"atm_dist\"] = (df[\"OPT_STRIKE_PX\"] - spot_px).abs()\n",
    "        df[\"OPT_PUT_CALL\"] = df[\"OPT_PUT_CALL\"].astype(str).str.upper()\n",
    "        atmC = df[df[\"OPT_PUT_CALL\"]==\"C\"].sort_values([\"atm_dist\",\"DTE\"]).groupby(\"OPT_EXPIRE_DT\").head(1)\n",
    "        atmP = df[df[\"OPT_PUT_CALL\"]==\"P\"].sort_values([\"atm_dist\",\"DTE\"]).groupby(\"OPT_EXPIRE_DT\").head(1)\n",
    "        pair = atmC.merge(atmP, on=\"OPT_EXPIRE_DT\", suffixes=(\"_C\",\"_P\"))\n",
    "        if pair.empty:\n",
    "            if verbose: print(\"[synthetic] Could not pair ATM call/put.\")\n",
    "            return pd.DataFrame()\n",
    "        pair[\"combo_dist\"] = pair[\"atm_dist_C\"] + pair[\"atm_dist_P\"]\n",
    "        best = pair.sort_values([\"combo_dist\",\"DTE_C\"]).head(1)\n",
    "\n",
    "        return pd.DataFrame([{\n",
    "            \"expiry\":   best[\"OPT_EXPIRE_DT\"].iloc[0],\n",
    "            \"DTE\":      int(best[\"DTE_C\"].iloc[0]),\n",
    "            \"call_tkr\": best[\"security_C\"].iloc[0],\n",
    "            \"put_tkr\":  best[\"security_P\"].iloc[0],\n",
    "            \"K\":        float(best[\"OPT_STRIKE_PX_C\"].iloc[0]),\n",
    "            \"C_mid\":    float(best[\"MID_C\"].iloc[0]),\n",
    "            \"P_mid\":    float(best[\"MID_P\"].iloc[0]),\n",
    "            \"IV_call\":  float(best[\"IMPLIED_VOLATILITY_C\"].iloc[0]) if pd.notna(best[\"IMPLIED_VOLATILITY_C\"].iloc[0]) else np.nan,\n",
    "            \"IV_put\":   float(best[\"IMPLIED_VOLATILITY_P\"].iloc[0]) if pd.notna(best[\"IMPLIED_VOLATILITY_P\"].iloc[0]) else np.nan\n",
    "        }])\n",
    "    finally:\n",
    "        s.stop()\n",
    "\n",
    "# -------------------- Quant helpers --------------------\n",
    "def black_scholes_price(S, K, T, r, sigma, cp):\n",
    "    d1 = (np.log(S/K) + (r + 0.5*sigma*sigma)*T)/(sigma*np.sqrt(T))\n",
    "    d2 = d1 - sigma*np.sqrt(T)\n",
    "    return (S*norm.cdf(d1) - K*np.exp(-r*T)*norm.cdf(d2)) if cp.upper()==\"C\" else (K*np.exp(-r*T)*norm.cdf(-d2) - S*norm.cdf(-d1))\n",
    "\n",
    "def realized_vol_from_close(close):\n",
    "    ret = np.log(close/close.shift(1)).dropna()\n",
    "    return ret.rolling(21).std()*np.sqrt(252)\n",
    "\n",
    "# -------------------- Backtest (unchanged interface, optional progress/sampling) --------------------\n",
    "def backtest_parity(\n",
    "    underlying=\"AAPL US Equity\",\n",
    "    start=\"20240101\",\n",
    "    end  =\"20250918\",\n",
    "    min_dte=25, max_dte=45,\n",
    "    gap_threshold=0.10,\n",
    "    max_hold_days=60,\n",
    "    riskfree_ticker=\"USGG3M Index\",\n",
    "    step_days=1,                # NEW: sample every N business days (1 = daily, 2 = every other day)\n",
    "    progress_every=10           # NEW: print progress every N steps (0 to silence)\n",
    "):\n",
    "    px = get_bdh_equity(underlying, start, end, fields=(\"PX_LAST\",))\n",
    "    rf = get_riskfree_series(start, end, ticker=riskfree_ticker)\n",
    "    df = px.join(rf, how=\"left\").fillna(method=\"ffill\")\n",
    "    df[\"rv_21\"] = realized_vol_from_close(df[\"PX_LAST\"])\n",
    "\n",
    "    trades, equity_curve = [], []\n",
    "    open_pos = None\n",
    "    dates = df.index.to_list()\n",
    "\n",
    "    for idx, dt in enumerate(dates):\n",
    "        if step_days > 1 and idx % step_days != 0:\n",
    "            equity_curve.append({\"date\": dt, \"equity\": 0.0 if not open_pos else open_pos[\"equity_mark\"]})\n",
    "            continue\n",
    "\n",
    "        S = float(df.loc[dt, \"PX_LAST\"])\n",
    "        rf_day = float(df.loc[dt, \"rf_daily\"]) if \"rf_daily\" in df.columns and pd.notna(df.loc[dt, \"rf_daily\"]) else 0.0\n",
    "\n",
    "        # carry open pos\n",
    "        if open_pos:\n",
    "            open_pos[\"days_held\"] += step_days\n",
    "            open_pos[\"cash\"] *= (1.0 + rf_day) ** step_days\n",
    "            equity_curve.append({\"date\": dt, \"equity\": open_pos[\"equity_mark\"]})\n",
    "        else:\n",
    "            equity_curve.append({\"date\": dt, \"equity\": 0.0})\n",
    "\n",
    "        # exit rules\n",
    "        if open_pos:\n",
    "            if dt >= open_pos[\"expiry\"] or open_pos[\"days_held\"] >= max_hold_days:\n",
    "                pnl = open_pos[\"gap_signed\"]\n",
    "                trades.append({**open_pos, \"exit_date\": dt, \"pnl\": pnl})\n",
    "                open_pos = None\n",
    "            continue\n",
    "\n",
    "        # chain lookup (now with built-in fallback)\n",
    "        chain = get_chain_for_day(underlying, S, dt, min_dte, max_dte, max_points=600, verbose=False)\n",
    "        if chain.empty:\n",
    "            if progress_every and idx % progress_every == 0:\n",
    "                print(f\"[{dt.date()}] No options found in DTE window ({min_dte}-{max_dte}).\")\n",
    "            continue\n",
    "\n",
    "        K    = chain[\"K\"].iloc[0]\n",
    "        Cmid = chain[\"C_mid\"].iloc[0]\n",
    "        Pmid = chain[\"P_mid\"].iloc[0]\n",
    "        expiry = chain[\"expiry\"].iloc[0]\n",
    "        dte   = int(chain[\"DTE\"].iloc[0])\n",
    "        T     = dte/365.0\n",
    "\n",
    "        r_ann = (df.loc[dt, \"rf_daily\"]*365.0) if \"rf_daily\" in df.columns and pd.notna(df.loc[dt, \"rf_daily\"]) else 0.0\n",
    "        dfac  = np.exp(-r_ann*T)\n",
    "        gap   = (Cmid - Pmid) - (S - K*dfac)\n",
    "\n",
    "        if abs(gap) < gap_threshold:\n",
    "            if progress_every and idx % progress_every == 0:\n",
    "                print(f\"[{dt.date()}] Gap {gap:.3f} < thr {gap_threshold}\")\n",
    "            continue\n",
    "\n",
    "        direction = \"short_call_long_put_shortS_longB\" if gap > 0 else \"long_call_short_put_longS_shortB\"\n",
    "        open_pos = {\n",
    "            \"entry_date\": dt, \"expiry\": expiry, \"days_held\": 0,\n",
    "            \"underlying\": underlying,\n",
    "            \"S0\": S, \"K\": K, \"C_mid0\": Cmid, \"P_mid0\": Pmid,\n",
    "            \"r_ann\": r_ann, \"T\": T, \"dte\": dte,\n",
    "            \"gap\": float(gap), \"gap_signed\": float(np.sign(gap)*abs(gap)),\n",
    "            \"direction\": direction,\n",
    "            \"cash\": K*dfac if gap>0 else -K*dfac,\n",
    "            \"equity_mark\": float(np.sign(gap)*abs(gap))\n",
    "        }\n",
    "\n",
    "        if progress_every and idx % progress_every == 0:\n",
    "            print(f\"[{dt.date()}] ENTER {direction} | DTE={dte} K={K:.2f} S={S:.2f} gap={gap:.3f}\")\n",
    "\n",
    "    eq = pd.DataFrame(equity_curve).set_index(\"date\")\n",
    "    tr = pd.DataFrame(trades)\n",
    "\n",
    "    if not tr.empty:\n",
    "        total_pnl = tr[\"pnl\"].sum()\n",
    "        hitrate   = (tr[\"pnl\"]>0).mean()\n",
    "        avg_hold  = tr[\"days_held\"].mean()\n",
    "    else:\n",
    "        total_pnl = 0.0; hitrate = np.nan; avg_hold = np.nan\n",
    "\n",
    "    return {\n",
    "        \"underlying_history\": df,\n",
    "        \"equity_curve\": eq,\n",
    "        \"trades\": tr,\n",
    "        \"summary\": {\n",
    "            \"total_pnl_units\": float(total_pnl),\n",
    "            \"num_trades\": int(len(tr)),\n",
    "            \"hit_ratio\": float(hitrate) if pd.notna(hitrate) else None,\n",
    "            \"avg_hold_days\": float(avg_hold) if pd.notna(avg_hold) else None\n",
    "        }\n",
    "    }\n",
    "\n",
    "# -------------------- Plot helper (skips flat plots) --------------------\n",
    "def plot_backtest(res, title=\"Parity Arbitrage Backtest\", outfile=None):\n",
    "    # no-trade guard\n",
    "    if not isinstance(res, dict) or \"summary\" not in res or res[\"summary\"].get(\"num_trades\", 0) == 0:\n",
    "        print(\"No trades â€” skipping plot.\")\n",
    "        return\n",
    "\n",
    "    uh = res[\"underlying_history\"].copy()\n",
    "    tr = res[\"trades\"].copy().set_index(\"exit_date\").sort_index()\n",
    "    daily = pd.Series(0.0, index=uh.index)\n",
    "    for dt, row in tr.iterrows():\n",
    "        if dt in daily.index:\n",
    "            daily.loc[dt] += float(row[\"pnl\"])\n",
    "    cum_pnl = daily.cumsum()\n",
    "    if outfile is None:\n",
    "        outfile = Path(f\"./backtest_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\")\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(cum_pnl.index, cum_pnl.values, linewidth=2)\n",
    "    plt.title(title); plt.xlabel(\"Date\"); plt.ylabel(\"Cumulative Realized PnL (units)\")\n",
    "    plt.grid(True, linewidth=0.5, alpha=0.6); plt.tight_layout()\n",
    "    plt.savefig(outfile, dpi=200); plt.close()\n",
    "    print(\"Saved chart to:\", outfile)\n",
    "\n",
    "# -------------------- Example run (same usage as before) --------------------\n",
    "underlying = \"PETR4 BZ Equity\"      # try \"VALE3 BZ Equity\", \"ITUB4 BZ Equity\", or a US name like \"AAPL US Equity\"\n",
    "start      = \"20240701\"\n",
    "end        = \"20240815\"\n",
    "min_dte, max_dte = 10, 60           # wider window helps on B3\n",
    "gap_threshold    = 0.05\n",
    "res = backtest_parity(\n",
    "    underlying=underlying,\n",
    "    start=start,\n",
    "    end=end,\n",
    "    min_dte=min_dte,\n",
    "    max_dte=max_dte,\n",
    "    gap_threshold=gap_threshold,\n",
    "    riskfree_ticker=\"BZSELIC Index\",\n",
    "    step_days=2,                     # sample every 2 business days for speed\n",
    "    progress_every=5                 # print heartbeat\n",
    ")\n",
    "print(\"Summary:\", res[\"summary\"])\n",
    "outfile = f\"{underlying.replace(' ','_')}_parity_backtest.png\"\n",
    "plot_backtest(res, title=f\"{underlying} Parity Arbitrage Backtest\", outfile=outfile)\n",
    "print(f\"Chart path: {outfile}\")\n",
    "# ==============================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "28c55bec-0a25-4a09-b9c8-d19c3743c6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-01] No options found in DTE window (10-60).\n",
      "[2024-07-16] No options found in DTE window (10-60).\n",
      "[2024-07-30] No options found in DTE window (10-60).\n",
      "[2024-08-13] No options found in DTE window (10-60).\n",
      "Summary: {'total_pnl_units': 0.0, 'num_trades': 0, 'hit_ratio': None, 'avg_hold_days': None}\n",
      "No trades â€” skipping plot.\n",
      "Chart path: AAPL_US_Equity_parity_backtest.png\n"
     ]
    }
   ],
   "source": [
    "# ======================= ALL-IN-ONE (Bloomberg parity backtest; BDP chain; cleaned warnings) =======================\n",
    "# Works on a Bloomberg Terminal PC (Desktop API; localhost:8194)\n",
    "# Public functions:\n",
    "#   get_bdh_equity, get_chain_for_day, backtest_parity, plot_backtest\n",
    "\n",
    "import blpapi, pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------- Bloomberg session helpers --------------------\n",
    "def _start_bbg_session(host=\"localhost\", port=8194):\n",
    "    so = blpapi.SessionOptions()\n",
    "    so.setServerHost(host); so.setServerPort(port)\n",
    "    s = blpapi.Session(so)\n",
    "    if not s.start(): raise RuntimeError(\"Failed to start Bloomberg session.\")\n",
    "    if not s.openService(\"//blp/refdata\"): raise RuntimeError(\"Failed to open //blp/refdata.\")\n",
    "    return s, s.getService(\"//blp/refdata\")\n",
    "\n",
    "def _send_req(session, req, timeout_ms=120_000):\n",
    "    session.sendRequest(req)\n",
    "    msgs = []\n",
    "    while True:\n",
    "        ev = session.nextEvent(timeout_ms)\n",
    "        for m in ev: msgs.append(m)\n",
    "        if ev.eventType() == blpapi.Event.RESPONSE:\n",
    "            break\n",
    "    return msgs\n",
    "\n",
    "# -------------------- Safe extractor for blpapi.Element --------------------\n",
    "def _blp_get(parent_el: blpapi.Element, field_name: str):\n",
    "    if not parent_el.hasElement(field_name):\n",
    "        return np.nan\n",
    "    sub = parent_el.getElement(field_name)\n",
    "    # numeric\n",
    "    for meth in (\"getValueAsFloat64\",\"getValueAsInt64\",\"getValueAsInteger\"):\n",
    "        try: return getattr(sub, meth)()\n",
    "        except Exception: pass\n",
    "    # other common types\n",
    "    for meth in (\"getValueAsBool\",\"getValueAsDatetime\",\"getValueAsString\"):\n",
    "        try:\n",
    "            val = getattr(sub, meth)()\n",
    "            if isinstance(val, blpapi.Datetime):\n",
    "                return pd.to_datetime(val.strftime(\"%Y-%m-%d\"))\n",
    "            return val\n",
    "        except Exception: pass\n",
    "    # fallback\n",
    "    try: return sub.getValue()\n",
    "    except Exception: return np.nan\n",
    "\n",
    "# -------------------- BDH: historical for any security (e.g., equity, rates) --------------------\n",
    "def get_bdh_equity(symbol_bbg, start_yyyymmdd, end_yyyymmdd, fields=(\"PX_LAST\",), periodicity=\"DAILY\"):\n",
    "    s, ref = _start_bbg_session()\n",
    "    try:\n",
    "        r = ref.createRequest(\"HistoricalDataRequest\")\n",
    "        r.getElement(\"securities\").appendValue(symbol_bbg)\n",
    "        fe = r.getElement(\"fields\")\n",
    "        for f in fields: fe.appendValue(f)\n",
    "        r.set(\"startDate\", start_yyyymmdd)\n",
    "        r.set(\"endDate\", end_yyyymmdd)\n",
    "        r.set(\"periodicitySelection\", periodicity)\n",
    "        msgs = _send_req(s, r)\n",
    "\n",
    "        rows = []\n",
    "        for msg in msgs:\n",
    "            if not msg.hasElement(\"securityData\"): continue\n",
    "            sd = msg.getElement(\"securityData\")\n",
    "            if not sd.hasElement(\"fieldData\"): continue\n",
    "            fd = sd.getElement(\"fieldData\")\n",
    "            for i in range(fd.numValues()):\n",
    "                row_el = fd.getValueAsElement(i)\n",
    "                d = row_el.getElementAsDatetime(\"date\")\n",
    "                out = {\"date\": pd.to_datetime(d.strftime(\"%Y-%m-%d\"))}\n",
    "                for f in fields:\n",
    "                    val = _blp_get(row_el, f)\n",
    "                    out[f] = val if val is not None else np.nan\n",
    "                rows.append(out)\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "        if df.empty:\n",
    "            return pd.DataFrame(columns=list(fields)).astype(float)\n",
    "        df = df.sort_values(\"date\").set_index(\"date\")\n",
    "        # coerce numerics without deprecated errors=\"ignore\"\n",
    "        for f in fields:\n",
    "            try:\n",
    "                df[f] = pd.to_numeric(df[f])\n",
    "            except Exception:\n",
    "                pass\n",
    "        return df\n",
    "    finally:\n",
    "        s.stop()\n",
    "\n",
    "def get_riskfree_series(start_yyyymmdd, end_yyyymmdd, ticker=\"USGG3M Index\"):\n",
    "    rf = get_bdh_equity(ticker, start_yyyymmdd, end_yyyymmdd, fields=(\"PX_LAST\",))\n",
    "    rf = rf.rename(columns={\"PX_LAST\":\"RF_YLD_PCT\"})\n",
    "    rf[\"rf_daily\"] = (rf[\"RF_YLD_PCT\"]/100.0)/365.0\n",
    "    return rf[[\"rf_daily\"]]\n",
    "\n",
    "# -------------------- Helper: parse BDP messages to DataFrame --------------------\n",
    "def _parse_bdp_messages_to_df(msgs, fields):\n",
    "    rows = []\n",
    "    for msg in msgs:\n",
    "        if not msg.hasElement(\"securityData\"):\n",
    "            continue\n",
    "        sdata = msg.getElement(\"securityData\")\n",
    "        for i in range(sdata.numValues()):\n",
    "            e = sdata.getValueAsElement(i)\n",
    "            sec = e.getElementAsString(\"security\")\n",
    "            if not e.hasElement(\"fieldData\"):\n",
    "                continue\n",
    "            fdata = e.getElement(\"fieldData\")\n",
    "            row = {\"security\": sec}\n",
    "            for f in fields:\n",
    "                row[f] = _blp_get(fdata, f)\n",
    "            rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# -------------------- Option chain (BDP-based synthetic scan; no CHAIN_TICKERS needed) --------------------\n",
    "def get_chain_for_day(\n",
    "    underlying_bbg,\n",
    "    spot_px,\n",
    "    trade_date,\n",
    "    target_min_dte=25,\n",
    "    target_max_dte=45,\n",
    "    max_points=None,         # accepted for compatibility; not used here\n",
    "    strike_band=0.20,        # Â±20% around spot\n",
    "    strike_step=1.0,         # $1 increments\n",
    "    max_strikes=101,         # safety cap (kept by band/step anyway)\n",
    "    verbose=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Build an options snapshot WITHOUT using CHAIN_TICKERS (works even when chain bulk field isn't entitled).\n",
    "    1) Create expiry candidates (nearest Fridays within DTE window).\n",
    "    2) Build strike ladder around spot.\n",
    "    3) Query BDP in bulk for both Calls and Puts, then pick ATM pair.\n",
    "\n",
    "    Returns a 1-row DataFrame with chosen ATM call/put or empty DF if none.\n",
    "    \"\"\"\n",
    "    # --- helpers ---\n",
    "    def _bbg_base(under):\n",
    "        # \"AAPL US Equity\" -> \"AAPL US\"\n",
    "        parts = under.split()\n",
    "        if len(parts) < 3:\n",
    "            raise ValueError(f\"Unexpected underlying format: {under}\")\n",
    "        return f\"{parts[0]} {parts[1]}\"\n",
    "\n",
    "    def _nearest_friday(d):\n",
    "        # Move to Friday of the same week (or next) depending on day\n",
    "        wd = d.weekday()  # Mon=0 ... Sun=6\n",
    "        if wd <= 4:\n",
    "            return d + timedelta(days=(4 - wd))\n",
    "        else:\n",
    "            # Sat/Sun -> next Friday\n",
    "            return d + timedelta(days=(11 - wd))\n",
    "\n",
    "    def _expiry_candidates(trade_dt, min_dte, max_dte):\n",
    "        # build a small set of Friday expiries (unique) inside [min_dte, max_dte]\n",
    "        exps = set()\n",
    "        for days_ahead in range(min_dte, max_dte + 1, 7):\n",
    "            exp = _nearest_friday(trade_dt + timedelta(days=days_ahead))\n",
    "            exps.add(exp)\n",
    "        # keep a handful (sorted)\n",
    "        exps = sorted(list(exps))\n",
    "        return exps[:8]  # limit to 8 expiries for speed\n",
    "\n",
    "    def _format_bbg_opt(base, exp_dt, cp, strike):\n",
    "        # Bloomberg std: \"<BASE> <MM/DD/YY> C123 Equity\"\n",
    "        mmddyy = exp_dt.strftime(\"%m/%d/%y\")\n",
    "        if abs(strike - round(strike)) < 1e-6:\n",
    "            strike_txt = str(int(round(strike)))\n",
    "        else:\n",
    "            strike_txt = f\"{strike:.2f}\".rstrip(\"0\").rstrip(\".\")\n",
    "        return f\"{base} {mmddyy} {cp}{strike_txt} Equity\"\n",
    "\n",
    "    # --- start session ---\n",
    "    s, ref = _start_bbg_session()\n",
    "    try:\n",
    "        base = _bbg_base(underlying_bbg)\n",
    "        trade_dt = pd.Timestamp(trade_date)\n",
    "        exps = _expiry_candidates(trade_dt, target_min_dte, target_max_dte)\n",
    "        if not exps:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # strike ladder around spot\n",
    "        lo = max(0.01, spot_px * (1.0 - strike_band))\n",
    "        hi = spot_px * (1.0 + strike_band)\n",
    "        step = max(0.01, float(strike_step))\n",
    "        strikes = np.arange(np.floor(lo), np.ceil(hi) + 1e-9, step)\n",
    "        if len(strikes) > max_strikes:\n",
    "            # thin evenly if dense\n",
    "            idx = np.linspace(0, len(strikes) - 1, max_strikes).round().astype(int)\n",
    "            strikes = strikes[idx]\n",
    "        strikes = np.unique(np.round(strikes, 2))\n",
    "\n",
    "        # Build bulk list of option tickers (Calls & Puts across expiries/strikes)\n",
    "        sec_list, meta = [], []\n",
    "        for exp in exps:\n",
    "            for cp in (\"C\", \"P\"):\n",
    "                for K in strikes:\n",
    "                    sec = _format_bbg_opt(base, exp, cp, K)\n",
    "                    sec_list.append(sec)\n",
    "                    meta.append({\"sec\": sec, \"cp\": cp, \"K\": float(K), \"expiry\": exp})\n",
    "        if not sec_list:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # BDP request\n",
    "        fields = [\n",
    "            \"PX_BID\",\"PX_ASK\",\n",
    "            \"OPT_STRIKE_PX\",\"OPT_EXPIRE_DT\",\"OPT_PUT_CALL\",\n",
    "            \"IVOL_MID\",                  # preferred\n",
    "            \"IMPLIED_VOLATILITY\"         # fallback\n",
    "        ]\n",
    "        bdp = ref.createRequest(\"ReferenceDataRequest\")\n",
    "        se = bdp.getElement(\"securities\"); [se.appendValue(sec) for sec in sec_list]\n",
    "        fe = bdp.getElement(\"fields\");     [fe.appendValue(f)   for f   in fields]\n",
    "        msgs = _send_req(s, bdp)\n",
    "\n",
    "        # parse\n",
    "        rows = []\n",
    "        meta_map = {m[\"sec\"]: m for m in meta}\n",
    "\n",
    "        def _get(fd, name):\n",
    "            if not fd.hasElement(name): return np.nan\n",
    "            sub = fd.getElement(name)\n",
    "            for meth in (\"getValueAsFloat64\",\"getValueAsInt64\",\"getValueAsInteger\"):\n",
    "                try: return getattr(sub, meth)()\n",
    "                except Exception: pass\n",
    "            for meth in (\"getValueAsDatetime\",\"getValueAsString\"):\n",
    "                try:\n",
    "                    val = getattr(sub, meth)()\n",
    "                    if isinstance(val, blpapi.Datetime):\n",
    "                        return pd.to_datetime(val.strftime(\"%Y-%m-%d\"))\n",
    "                    return val\n",
    "                except Exception: pass\n",
    "            try: return sub.getValue()\n",
    "            except Exception: return np.nan\n",
    "\n",
    "        for msg in msgs:\n",
    "            if not msg.hasElement(\"securityData\"): continue\n",
    "            sdata = msg.getElement(\"securityData\")\n",
    "            for i in range(sdata.numValues()):\n",
    "                e = sdata.getValueAsElement(i)\n",
    "                sec = e.getElementAsString(\"security\")\n",
    "                if not e.hasElement(\"fieldData\"): continue\n",
    "                fd = e.getElement(\"fieldData\")\n",
    "\n",
    "                bid = pd.to_numeric(_get(fd, \"PX_BID\"), errors=\"coerce\")\n",
    "                ask = pd.to_numeric(_get(fd, \"PX_ASK\"), errors=\"coerce\")\n",
    "                if pd.isna(bid) and pd.isna(ask):\n",
    "                    continue  # dead quote\n",
    "\n",
    "                Kfd  = _get(fd, \"OPT_STRIKE_PX\")\n",
    "                Efd  = _get(fd, \"OPT_EXPIRE_DT\")\n",
    "                PCfd = _get(fd, \"OPT_PUT_CALL\")\n",
    "                iv1  = _get(fd, \"IVOL_MID\")\n",
    "                iv2  = _get(fd, \"IMPLIED_VOLATILITY\")\n",
    "\n",
    "                meta_row = meta_map.get(sec, {})\n",
    "                K = float(Kfd) if pd.notna(Kfd) else meta_row.get(\"K\", np.nan)\n",
    "                E = (Efd if isinstance(Efd, pd.Timestamp) else\n",
    "                     (pd.to_datetime(Efd) if pd.notna(Efd) else meta_row.get(\"expiry\", np.nan)))\n",
    "                cp = (str(PCfd).upper() if isinstance(PCfd, str) else meta_row.get(\"cp\", None))\n",
    "\n",
    "                rows.append({\n",
    "                    \"security\": sec,\n",
    "                    \"OPT_STRIKE_PX\": K,\n",
    "                    \"OPT_EXPIRE_DT\": E,\n",
    "                    \"OPT_PUT_CALL\": cp,\n",
    "                    \"PX_BID\": float(bid) if pd.notna(bid) else np.nan,\n",
    "                    \"PX_ASK\": float(ask) if pd.notna(ask) else np.nan,\n",
    "                    \"MID\": np.nan if (pd.isna(bid) or pd.isna(ask)) else (float(bid)+float(ask))/2.0,\n",
    "                    \"IMPLIED_VOLATILITY\": (pd.to_numeric(iv1, errors=\"coerce\")\n",
    "                                           if pd.notna(iv1) else pd.to_numeric(iv2, errors=\"coerce\"))\n",
    "                })\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "        if df.empty:\n",
    "            if verbose: print(\"[synthetic] No options returned via BDP.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Clean & filter by DTE\n",
    "        df = df.dropna(subset=[\"OPT_STRIKE_PX\",\"OPT_EXPIRE_DT\",\"OPT_PUT_CALL\",\"MID\"]).copy()\n",
    "        df[\"OPT_EXPIRE_DT\"] = pd.to_datetime(df[\"OPT_EXPIRE_DT\"], errors=\"coerce\")\n",
    "        trade_dt = pd.Timestamp(trade_date)\n",
    "        df[\"DTE\"] = (df[\"OPT_EXPIRE_DT\"] - trade_dt).dt.days\n",
    "        df = df[(df[\"DTE\"]>=target_min_dte) & (df[\"DTE\"]<=target_max_dte)]\n",
    "        if df.empty:\n",
    "            if verbose: print(\"[synthetic] All candidates filtered out by DTE window.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Pick ATM C & P from each expiry; then best pair overall\n",
    "        df[\"atm_dist\"] = (df[\"OPT_STRIKE_PX\"] - spot_px).abs()\n",
    "        df[\"OPT_PUT_CALL\"] = df[\"OPT_PUT_CALL\"].astype(str).str.upper()\n",
    "        atmC = df[df[\"OPT_PUT_CALL\"]==\"C\"].sort_values([\"atm_dist\",\"DTE\"]).groupby(\"OPT_EXPIRE_DT\").head(1)\n",
    "        atmP = df[df[\"OPT_PUT_CALL\"]==\"P\"].sort_values([\"atm_dist\",\"DTE\"]).groupby(\"OPT_EXPIRE_DT\").head(1)\n",
    "        pair = atmC.merge(atmP, on=\"OPT_EXPIRE_DT\", suffixes=(\"_C\",\"_P\"))\n",
    "        if pair.empty:\n",
    "            if verbose: print(\"[synthetic] Could not pair ATM call/put.\")\n",
    "            return pd.DataFrame()\n",
    "        pair[\"combo_dist\"] = pair[\"atm_dist_C\"] + pair[\"atm_dist_P\"]\n",
    "        best = pair.sort_values([\"combo_dist\",\"DTE_C\"]).head(1)\n",
    "\n",
    "        return pd.DataFrame([{\n",
    "            \"expiry\":   best[\"OPT_EXPIRE_DT\"].iloc[0],\n",
    "            \"DTE\":      int(best[\"DTE_C\"].iloc[0]),\n",
    "            \"call_tkr\": best[\"security_C\"].iloc[0],\n",
    "            \"put_tkr\":  best[\"security_P\"].iloc[0],\n",
    "            \"K\":        float(best[\"OPT_STRIKE_PX_C\"].iloc[0]),\n",
    "            \"C_mid\":    float(best[\"MID_C\"].iloc[0]),\n",
    "            \"P_mid\":    float(best[\"MID_P\"].iloc[0]),\n",
    "            \"IV_call\":  float(best[\"IMPLIED_VOLATILITY_C\"].iloc[0]) if pd.notna(best[\"IMPLIED_VOLATILITY_C\"].iloc[0]) else np.nan,\n",
    "            \"IV_put\":   float(best[\"IMPLIED_VOLATILITY_P\"].iloc[0]) if pd.notna(best[\"IMPLIED_VOLATILITY_P\"].iloc[0]) else np.nan\n",
    "        }])\n",
    "    finally:\n",
    "        s.stop()\n",
    "\n",
    "# -------------------- Quant helpers --------------------\n",
    "def black_scholes_price(S, K, T, r, sigma, cp):\n",
    "    d1 = (np.log(S/K) + (r + 0.5*sigma*sigma)*T)/(sigma*np.sqrt(T))\n",
    "    d2 = d1 - sigma*np.sqrt(T)\n",
    "    return (S*norm.cdf(d1) - K*np.exp(-r*T)*norm.cdf(d2)) if cp.upper()==\"C\" else (K*np.exp(-r*T)*norm.cdf(-d2) - S*norm.cdf(-d1))\n",
    "\n",
    "def realized_vol_from_close(close):\n",
    "    ret = np.log(close/close.shift(1)).dropna()\n",
    "    return ret.rolling(21).std()*np.sqrt(252)\n",
    "\n",
    "# -------------------- Backtest (unchanged interface; progress/sampling) --------------------\n",
    "def backtest_parity(\n",
    "    underlying=\"AAPL US Equity\",\n",
    "    start=\"20240101\",\n",
    "    end  =\"20250918\",\n",
    "    min_dte=25, max_dte=45,\n",
    "    gap_threshold=0.10,\n",
    "    max_hold_days=60,\n",
    "    riskfree_ticker=\"USGG3M Index\",\n",
    "    step_days=1,                # sample every N business days (1 = daily)\n",
    "    progress_every=10           # print progress every N steps (0 to silence)\n",
    "):\n",
    "    px = get_bdh_equity(underlying, start, end, fields=(\"PX_LAST\",))\n",
    "    rf = get_riskfree_series(start, end, ticker=riskfree_ticker)\n",
    "    # forward-fill with new API\n",
    "    df = px.join(rf, how=\"left\").ffill()\n",
    "    df[\"rv_21\"] = realized_vol_from_close(df[\"PX_LAST\"])\n",
    "\n",
    "    trades, equity_curve = [], []\n",
    "    open_pos = None\n",
    "    dates = df.index.to_list()\n",
    "\n",
    "    for idx, dt in enumerate(dates):\n",
    "        if step_days > 1 and idx % step_days != 0:\n",
    "            equity_curve.append({\"date\": dt, \"equity\": 0.0 if not open_pos else open_pos[\"equity_mark\"]})\n",
    "            continue\n",
    "\n",
    "        S = float(df.loc[dt, \"PX_LAST\"])\n",
    "        rf_day = float(df.loc[dt, \"rf_daily\"]) if \"rf_daily\" in df.columns and pd.notna(df.loc[dt, \"rf_daily\"]) else 0.0\n",
    "\n",
    "        # carry open pos\n",
    "        if open_pos:\n",
    "            open_pos[\"days_held\"] += step_days\n",
    "            open_pos[\"cash\"] *= (1.0 + rf_day) ** step_days\n",
    "            equity_curve.append({\"date\": dt, \"equity\": open_pos[\"equity_mark\"]})\n",
    "        else:\n",
    "            equity_curve.append({\"date\": dt, \"equity\": 0.0})\n",
    "\n",
    "        # exit rules\n",
    "        if open_pos:\n",
    "            if dt >= open_pos[\"expiry\"] or open_pos[\"days_held\"] >= max_hold_days:\n",
    "                pnl = open_pos[\"gap_signed\"]\n",
    "                trades.append({**open_pos, \"exit_date\": dt, \"pnl\": pnl})\n",
    "                open_pos = None\n",
    "            continue\n",
    "\n",
    "        # chain lookup (BDP synthetic; max_points accepted but ignored)\n",
    "        chain = get_chain_for_day(underlying, S, dt, min_dte, max_dte, max_points=600, verbose=False)\n",
    "        if chain.empty:\n",
    "            if progress_every and idx % progress_every == 0:\n",
    "                print(f\"[{dt.date()}] No options found in DTE window ({min_dte}-{max_dte}).\")\n",
    "            continue\n",
    "\n",
    "        K    = chain[\"K\"].iloc[0]\n",
    "        Cmid = chain[\"C_mid\"].iloc[0]\n",
    "        Pmid = chain[\"P_mid\"].iloc[0]\n",
    "        expiry = chain[\"expiry\"].iloc[0]\n",
    "        dte   = int(chain[\"DTE\"].iloc[0])\n",
    "        T     = dte/365.0\n",
    "\n",
    "        r_ann = (df.loc[dt, \"rf_daily\"]*365.0) if \"rf_daily\" in df.columns and pd.notna(df.loc[dt, \"rf_daily\"]) else 0.0\n",
    "        dfac  = np.exp(-r_ann*T)\n",
    "        gap   = (Cmid - Pmid) - (S - K*dfac)\n",
    "\n",
    "        if abs(gap) < gap_threshold:\n",
    "            if progress_every and idx % progress_every == 0:\n",
    "                print(f\"[{dt.date()}] Gap {gap:.3f} < thr {gap_threshold}\")\n",
    "            continue\n",
    "\n",
    "        direction = \"short_call_long_put_shortS_longB\" if gap > 0 else \"long_call_short_put_longS_shortB\"\n",
    "        open_pos = {\n",
    "            \"entry_date\": dt, \"expiry\": expiry, \"days_held\": 0,\n",
    "            \"underlying\": underlying,\n",
    "            \"S0\": S, \"K\": K, \"C_mid0\": Cmid, \"P_mid0\": Pmid,\n",
    "            \"r_ann\": r_ann, \"T\": T, \"dte\": dte,\n",
    "            \"gap\": float(gap), \"gap_signed\": float(np.sign(gap)*abs(gap)),\n",
    "            \"direction\": direction,\n",
    "            \"cash\": K*dfac if gap>0 else -K*dfac,\n",
    "            \"equity_mark\": float(np.sign(gap)*abs(gap))\n",
    "        }\n",
    "\n",
    "        if progress_every and idx % progress_every == 0:\n",
    "            print(f\"[{dt.date()}] ENTER {direction} | DTE={dte} K={K:.2f} S={S:.2f} gap={gap:.3f}\")\n",
    "\n",
    "    eq = pd.DataFrame(equity_curve).set_index(\"date\")\n",
    "    tr = pd.DataFrame(trades)\n",
    "\n",
    "    if not tr.empty:\n",
    "        total_pnl = tr[\"pnl\"].sum()\n",
    "        hitrate   = (tr[\"pnl\"]>0).mean()\n",
    "        avg_hold  = tr[\"days_held\"].mean()\n",
    "    else:\n",
    "        total_pnl = 0.0; hitrate = np.nan; avg_hold = np.nan\n",
    "\n",
    "    return {\n",
    "        \"underlying_history\": df,\n",
    "        \"equity_curve\": eq,\n",
    "        \"trades\": tr,\n",
    "        \"summary\": {\n",
    "            \"total_pnl_units\": float(total_pnl),\n",
    "            \"num_trades\": int(len(tr)),\n",
    "            \"hit_ratio\": float(hitrate) if pd.notna(hitrate) else None,\n",
    "            \"avg_hold_days\": float(avg_hold) if pd.notna(avg_hold) else None\n",
    "        }\n",
    "    }\n",
    "\n",
    "# -------------------- Plot helper (skips flat plots) --------------------\n",
    "def plot_backtest(res, title=\"Parity Arbitrage Backtest\", outfile=None):\n",
    "    # no-trade guard\n",
    "    if not isinstance(res, dict) or \"summary\" not in res or res[\"summary\"].get(\"num_trades\", 0) == 0:\n",
    "        print(\"No trades â€” skipping plot.\")\n",
    "        return\n",
    "\n",
    "    uh = res[\"underlying_history\"].copy()\n",
    "    tr = res[\"trades\"].copy().set_index(\"exit_date\").sort_index() if not res[\"trades\"].empty else pd.DataFrame()\n",
    "    daily = pd.Series(0.0, index=uh.index)\n",
    "    if not tr.empty:\n",
    "        for dt, row in tr.iterrows():\n",
    "            if dt in daily.index:\n",
    "                daily.loc[dt] += float(row[\"pnl\"])\n",
    "    cum_pnl = daily.cumsum()\n",
    "    if outfile is None:\n",
    "        outfile = Path(f\"./backtest_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\")\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(cum_pnl.index, cum_pnl.values, linewidth=2)\n",
    "    plt.title(title); plt.xlabel(\"Date\"); plt.ylabel(\"Cumulative Realized PnL (units)\")\n",
    "    plt.grid(True, linewidth=0.5, alpha=0.6); plt.tight_layout()\n",
    "    plt.savefig(outfile, dpi=200); plt.close()\n",
    "    print(\"Saved chart to:\", outfile)\n",
    "\n",
    "# -------------------- Example run --------------------\n",
    "underlying = \"AAPL US Equity\"        # e.g., \"MSFT US Equity\", \"SPY US Equity\"; BZ names may require local entitlements\n",
    "start      = \"20240701\"\n",
    "end        = \"20240815\"\n",
    "min_dte, max_dte = 10, 60\n",
    "gap_threshold    = 0.05\n",
    "\n",
    "res = backtest_parity(\n",
    "    underlying=underlying,\n",
    "    start=start,\n",
    "    end=end,\n",
    "    min_dte=min_dte,\n",
    "    max_dte=max_dte,\n",
    "    gap_threshold=gap_threshold,\n",
    "    riskfree_ticker=\"USGG3M Index\",\n",
    "    step_days=2,\n",
    "    progress_every=5\n",
    ")\n",
    "print(\"Summary:\", res[\"summary\"])\n",
    "outfile = f\"{underlying.replace(' ','_')}_parity_backtest.png\"\n",
    "plot_backtest(res, title=f\"{underlying} Parity Arbitrage Backtest\", outfile=outfile)\n",
    "print(f\"Chart path: {outfile}\")\n",
    "# ==============================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c03ee423-40f1-4c0d-ba26-10d20048c1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[chain] expiries candidates: 13 (min_dte=10, max_dte=60)\n",
      "[chain] strike candidates around spot 216.00: 13\n",
      "[chain] requesting 338 option securities via BDP\n",
      "[chain] returned: 338, with quotes: 0, with last-only: 0\n",
      "[chain] No valid options returned via BDP.\n",
      "[2024-07-01] No options found in DTE window (10-60).\n",
      "[chain] expiries candidates: 12 (min_dte=10, max_dte=60)\n",
      "[chain] strike candidates around spot 221.00: 13\n",
      "[chain] requesting 312 option securities via BDP\n",
      "[chain] returned: 312, with quotes: 0, with last-only: 0\n",
      "[chain] No valid options returned via BDP.\n",
      "[chain] expiries candidates: 13 (min_dte=10, max_dte=60)\n",
      "[chain] strike candidates around spot 227.00: 13\n",
      "[chain] requesting 338 option securities via BDP\n",
      "[chain] returned: 338, with quotes: 0, with last-only: 0\n",
      "[chain] No valid options returned via BDP.\n",
      "[chain] expiries candidates: 12 (min_dte=10, max_dte=60)\n",
      "[chain] strike candidates around spot 232.00: 13\n",
      "[chain] requesting 312 option securities via BDP\n",
      "[chain] returned: 312, with quotes: 0, with last-only: 0\n",
      "[chain] No valid options returned via BDP.\n",
      "[chain] expiries candidates: 12 (min_dte=10, max_dte=60)\n",
      "[chain] strike candidates around spot 230.00: 13\n",
      "[chain] requesting 312 option securities via BDP\n",
      "[chain] returned: 312, with quotes: 0, with last-only: 0\n",
      "[chain] No valid options returned via BDP.\n",
      "[chain] expiries candidates: 13 (min_dte=10, max_dte=60)\n",
      "[chain] strike candidates around spot 234.00: 13\n",
      "[chain] requesting 338 option securities via BDP\n",
      "[chain] returned: 338, with quotes: 0, with last-only: 0\n",
      "[chain] No valid options returned via BDP.\n",
      "[2024-07-16] No options found in DTE window (10-60).\n",
      "[chain] expiries candidates: 12 (min_dte=10, max_dte=60)\n",
      "[chain] strike candidates around spot 224.00: 13\n",
      "[chain] requesting 312 option securities via BDP\n",
      "[chain] returned: 312, with quotes: 0, with last-only: 0\n",
      "[chain] No valid options returned via BDP.\n",
      "[chain] expiries candidates: 12 (min_dte=10, max_dte=60)\n",
      "[chain] strike candidates around spot 223.00: 13\n",
      "[chain] requesting 312 option securities via BDP\n",
      "[chain] returned: 312, with quotes: 0, with last-only: 0\n",
      "[chain] No valid options returned via BDP.\n",
      "[chain] expiries candidates: 11 (min_dte=10, max_dte=60)\n",
      "[chain] strike candidates around spot 218.00: 13\n",
      "[chain] requesting 286 option securities via BDP\n",
      "[chain] returned: 286, with quotes: 0, with last-only: 0\n",
      "[chain] No valid options returned via BDP.\n",
      "[chain] expiries candidates: 11 (min_dte=10, max_dte=60)\n",
      "[chain] strike candidates around spot 217.00: 13\n",
      "[chain] requesting 286 option securities via BDP\n",
      "[chain] returned: 286, with quotes: 0, with last-only: 0\n",
      "[chain] No valid options returned via BDP.\n",
      "[chain] expiries candidates: 12 (min_dte=10, max_dte=60)\n",
      "[chain] strike candidates around spot 218.00: 13\n",
      "[chain] requesting 312 option securities via BDP\n",
      "[chain] returned: 312, with quotes: 0, with last-only: 0\n",
      "[chain] No valid options returned via BDP.\n",
      "[2024-07-30] No options found in DTE window (10-60).\n",
      "[chain] expiries candidates: 12 (min_dte=10, max_dte=60)\n",
      "[chain] strike candidates around spot 218.00: 13\n",
      "[chain] requesting 312 option securities via BDP\n",
      "[chain] returned: 312, with quotes: 0, with last-only: 0\n",
      "[chain] No valid options returned via BDP.\n",
      "[chain] expiries candidates: 13 (min_dte=10, max_dte=60)\n",
      "[chain] strike candidates around spot 209.00: 13\n",
      "[chain] requesting 338 option securities via BDP\n",
      "[chain] returned: 338, with quotes: 0, with last-only: 0\n",
      "[chain] No valid options returned via BDP.\n",
      "[chain] expiries candidates: 12 (min_dte=10, max_dte=60)\n",
      "[chain] strike candidates around spot 209.00: 13\n",
      "[chain] requesting 312 option securities via BDP\n",
      "[chain] returned: 312, with quotes: 0, with last-only: 0\n",
      "[chain] No valid options returned via BDP.\n",
      "[chain] expiries candidates: 12 (min_dte=10, max_dte=60)\n",
      "[chain] strike candidates around spot 216.00: 13\n",
      "[chain] requesting 312 option securities via BDP\n",
      "[chain] returned: 312, with quotes: 0, with last-only: 0\n",
      "[chain] No valid options returned via BDP.\n",
      "[chain] expiries candidates: 13 (min_dte=10, max_dte=60)\n",
      "[chain] strike candidates around spot 221.00: 13\n",
      "[chain] requesting 338 option securities via BDP\n",
      "[chain] returned: 338, with quotes: 0, with last-only: 0\n",
      "[chain] No valid options returned via BDP.\n",
      "[2024-08-13] No options found in DTE window (10-60).\n",
      "[chain] expiries candidates: 12 (min_dte=10, max_dte=60)\n",
      "[chain] strike candidates around spot 224.00: 13\n",
      "[chain] requesting 312 option securities via BDP\n",
      "[chain] returned: 312, with quotes: 0, with last-only: 0\n",
      "[chain] No valid options returned via BDP.\n",
      "Summary: {'total_pnl_units': 0.0, 'num_trades': 0, 'hit_ratio': None, 'avg_hold_days': None}\n",
      "No trades â€” skipping plot.\n",
      "Chart path: AAPL_US_Equity_parity_backtest.png\n"
     ]
    }
   ],
   "source": [
    "# ======================= ALL-IN-ONE (Bloomberg parity backtest; robust BDP chain scan) =======================\n",
    "# Works on a Bloomberg Terminal PC (Desktop API; localhost:8194)\n",
    "# Public functions:\n",
    "#   get_bdh_equity, get_chain_for_day, backtest_parity, plot_backtest\n",
    "\n",
    "import blpapi, pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------- Bloomberg session helpers --------------------\n",
    "def _start_bbg_session(host=\"localhost\", port=8194):\n",
    "    so = blpapi.SessionOptions()\n",
    "    so.setServerHost(host); so.setServerPort(port)\n",
    "    s = blpapi.Session(so)\n",
    "    if not s.start(): raise RuntimeError(\"Failed to start Bloomberg session.\")\n",
    "    if not s.openService(\"//blp/refdata\"): raise RuntimeError(\"Failed to open //blp/refdata.\")\n",
    "    return s, s.getService(\"//blp/refdata\")\n",
    "\n",
    "def _send_req(session, req, timeout_ms=120_000):\n",
    "    session.sendRequest(req)\n",
    "    msgs = []\n",
    "    while True:\n",
    "        ev = session.nextEvent(timeout_ms)\n",
    "        for m in ev: msgs.append(m)\n",
    "        if ev.eventType() == blpapi.Event.RESPONSE:\n",
    "            break\n",
    "    return msgs\n",
    "\n",
    "# -------------------- Safe extractor for blpapi.Element --------------------\n",
    "def _blp_get(parent_el: blpapi.Element, field_name: str):\n",
    "    if not parent_el.hasElement(field_name):\n",
    "        return np.nan\n",
    "    sub = parent_el.getElement(field_name)\n",
    "    for meth in (\"getValueAsFloat64\",\"getValueAsInt64\",\"getValueAsInteger\"):\n",
    "        try: return getattr(sub, meth)()\n",
    "        except Exception: pass\n",
    "    for meth in (\"getValueAsBool\",\"getValueAsDatetime\",\"getValueAsString\"):\n",
    "        try:\n",
    "            val = getattr(sub, meth)()\n",
    "            if isinstance(val, blpapi.Datetime):\n",
    "                return pd.to_datetime(val.strftime(\"%Y-%m-%d\"))\n",
    "            return val\n",
    "        except Exception: pass\n",
    "    try: return sub.getValue()\n",
    "    except Exception: return np.nan\n",
    "\n",
    "# -------------------- BDH: historical for any security (e.g., equity, rates) --------------------\n",
    "def get_bdh_equity(symbol_bbg, start_yyyymmdd, end_yyyymmdd, fields=(\"PX_LAST\",), periodicity=\"DAILY\"):\n",
    "    s, ref = _start_bbg_session()\n",
    "    try:\n",
    "        r = ref.createRequest(\"HistoricalDataRequest\")\n",
    "        r.getElement(\"securities\").appendValue(symbol_bbg)\n",
    "        fe = r.getElement(\"fields\")\n",
    "        for f in fields: fe.appendValue(f)\n",
    "        r.set(\"startDate\", start_yyyymmdd)\n",
    "        r.set(\"endDate\", end_yyyymmdd)\n",
    "        r.set(\"periodicitySelection\", periodicity)\n",
    "        msgs = _send_req(s, r)\n",
    "\n",
    "        rows = []\n",
    "        for msg in msgs:\n",
    "            if not msg.hasElement(\"securityData\"): continue\n",
    "            sd = msg.getElement(\"securityData\")\n",
    "            if not sd.hasElement(\"fieldData\"): continue\n",
    "            fd = sd.getElement(\"fieldData\")\n",
    "            for i in range(fd.numValues()):\n",
    "                row_el = fd.getValueAsElement(i)\n",
    "                d = row_el.getElementAsDatetime(\"date\")\n",
    "                out = {\"date\": pd.to_datetime(d.strftime(\"%Y-%m-%d\"))}\n",
    "                for f in fields:\n",
    "                    val = _blp_get(row_el, f)\n",
    "                    out[f] = val if val is not None else np.nan\n",
    "                rows.append(out)\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "        if df.empty:\n",
    "            return pd.DataFrame(columns=list(fields)).astype(float)\n",
    "        df = df.sort_values(\"date\").set_index(\"date\")\n",
    "        for f in fields:\n",
    "            try: df[f] = pd.to_numeric(df[f])\n",
    "            except Exception: pass\n",
    "        return df\n",
    "    finally:\n",
    "        s.stop()\n",
    "\n",
    "def get_riskfree_series(start_yyyymmdd, end_yyyymmdd, ticker=\"USGG3M Index\"):\n",
    "    rf = get_bdh_equity(ticker, start_yyyymmdd, end_yyyymmdd, fields=(\"PX_LAST\",))\n",
    "    rf = rf.rename(columns={\"PX_LAST\":\"RF_YLD_PCT\"})\n",
    "    rf[\"rf_daily\"] = (rf[\"RF_YLD_PCT\"]/100.0)/365.0\n",
    "    return rf[[\"rf_daily\"]]\n",
    "\n",
    "# -------------------- Option chain (heavy-duty BDP scan; no CHAIN_TICKERS needed) --------------------\n",
    "def get_chain_for_day(\n",
    "    underlying_bbg,\n",
    "    spot_px,\n",
    "    trade_date,\n",
    "    target_min_dte=25,\n",
    "    target_max_dte=45,\n",
    "    max_points=None,         # accepted for compatibility; not used\n",
    "    verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Robust BDP scanner (no CHAIN_TICKERS):\n",
    "      â€¢ Expiries: all Fridays in [min_dte, max_dte] + next 6 third-Fridays (monthlies)\n",
    "      â€¢ Strikes: price-aware ATM ladder (0.5/1/2.5/5/10 increments), a few steps each side\n",
    "      â€¢ Pricing: prefer BID/ASK -> MID; fallback to LAST_PRICE when quotes are unavailable\n",
    "\n",
    "    Returns a 1-row DataFrame with the chosen ATM call/put, or empty DF if none.\n",
    "    \"\"\"\n",
    "    import pandas as pd, numpy as np, blpapi\n",
    "    from datetime import timedelta\n",
    "\n",
    "    # ---- helpers ----\n",
    "    def _bbg_base(under):\n",
    "        parts = under.split()\n",
    "        if len(parts) < 3:\n",
    "            raise ValueError(f\"Unexpected underlying format: {under}\")\n",
    "        return f\"{parts[0]} {parts[1]}\"\n",
    "\n",
    "    def _fridays_between(start_dt, min_dte, max_dte):\n",
    "        fr = []\n",
    "        for d in range(min_dte, max_dte + 1):\n",
    "            dt = start_dt + timedelta(days=d)\n",
    "            if dt.weekday() == 4:  # Friday\n",
    "                fr.append(dt)\n",
    "        return fr\n",
    "\n",
    "    def _third_fridays(start_dt, count=6):\n",
    "        exps, dt = [], start_dt\n",
    "        while len(exps) < count:\n",
    "            y, m = dt.year + (dt.month // 12), (dt.month % 12) + 1\n",
    "            first_next = pd.Timestamp(year=y, month=m, day=1)\n",
    "            wd = first_next.weekday()\n",
    "            first_friday = first_next + timedelta(days=(4 - wd) % 7)\n",
    "            third_friday = first_friday + timedelta(days=14)\n",
    "            exps.append(third_friday)\n",
    "            dt = third_friday\n",
    "        return exps\n",
    "\n",
    "    def _strike_increment(S):\n",
    "        if S < 25:   return 0.5\n",
    "        if S < 200:  return 1.0\n",
    "        if S < 500:  return 2.5\n",
    "        if S < 1000: return 5.0\n",
    "        return 10.0\n",
    "\n",
    "    def _atm_ladder(S, steps=5):\n",
    "        inc = _strike_increment(S)\n",
    "        k0  = round(S / inc) * inc\n",
    "        ks  = [k0 + i*inc for i in range(-steps, steps+1)]\n",
    "        coarse = [k0 + i*(5*inc) for i in range(-2, 3)]\n",
    "        ks = sorted(set([round(k, 2) for k in ks + coarse]))\n",
    "        return ks\n",
    "\n",
    "    def _format_bbg_opt(base, exp_dt, cp, strike):\n",
    "        mmddyy = pd.Timestamp(exp_dt).strftime(\"%m/%d/%y\")\n",
    "        if abs(strike - round(strike)) < 1e-6:\n",
    "            strike_txt = str(int(round(strike)))\n",
    "        else:\n",
    "            strike_txt = f\"{strike:.2f}\".rstrip(\"0\").rstrip(\".\")\n",
    "        return f\"{base} {mmddyy} {cp}{strike_txt} Equity\"\n",
    "\n",
    "    # ---- assemble candidates ----\n",
    "    base = _bbg_base(underlying_bbg)\n",
    "    trade_dt = pd.Timestamp(trade_date)\n",
    "\n",
    "    expiry_fridays   = _fridays_between(trade_dt, target_min_dte, target_max_dte)\n",
    "    expiry_monthlies = _third_fridays(trade_dt, count=6)\n",
    "    expiries = sorted(set(expiry_fridays + expiry_monthlies))[:24]  # cap\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"[chain] expiries candidates: {len(expiries)} (min_dte={target_min_dte}, max_dte={target_max_dte})\")\n",
    "\n",
    "    if not expiries:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    strikes = _atm_ladder(spot_px, steps=5)\n",
    "    if verbose:\n",
    "        print(f\"[chain] strike candidates around spot {spot_px:.2f}: {len(strikes)}\")\n",
    "\n",
    "    sec_list, meta = [], []\n",
    "    for exp in expiries:\n",
    "        for cp in (\"C\", \"P\"):\n",
    "            for K in strikes:\n",
    "                sec = _format_bbg_opt(base, exp, cp, K)\n",
    "                sec_list.append(sec)\n",
    "                meta.append({\"sec\": sec, \"cp\": cp, \"K\": float(K), \"expiry\": pd.Timestamp(exp)})\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"[chain] requesting {len(sec_list)} option securities via BDP\")\n",
    "\n",
    "    # ---- BDP request (use BID/ASK + LAST_PRICE) ----\n",
    "    s, ref = _start_bbg_session()\n",
    "    try:\n",
    "        fields = [\n",
    "            \"BID\",\"ASK\",\"LAST_PRICE\",\n",
    "            \"OPT_STRIKE_PX\",\"OPT_EXPIRE_DT\",\"OPT_PUT_CALL\",\n",
    "            \"IVOL_MID\",\"IMPLIED_VOLATILITY\"\n",
    "        ]\n",
    "        bdp = ref.createRequest(\"ReferenceDataRequest\")\n",
    "        se = bdp.getElement(\"securities\"); [se.appendValue(sec) for sec in sec_list]\n",
    "        fe = bdp.getElement(\"fields\");     [fe.appendValue(f)   for f   in fields]\n",
    "        msgs = _send_req(s, bdp)\n",
    "\n",
    "        rows = []\n",
    "        meta_map = {m[\"sec\"]: m for m in meta}\n",
    "\n",
    "        def _get(fd, name):\n",
    "            if not fd.hasElement(name): return np.nan\n",
    "            sub = fd.getElement(name)\n",
    "            for meth in (\"getValueAsFloat64\",\"getValueAsInt64\",\"getValueAsInteger\"):\n",
    "                try: return getattr(sub, meth)()\n",
    "                except Exception: pass\n",
    "            for meth in (\"getValueAsDatetime\",\"getValueAsString\"):\n",
    "                try:\n",
    "                    val = getattr(sub, meth)()\n",
    "                    if isinstance(val, blpapi.Datetime):\n",
    "                        return pd.to_datetime(val.strftime(\"%Y-%m-%d\"))\n",
    "                    return val\n",
    "                except Exception: pass\n",
    "            try: return sub.getValue()\n",
    "            except Exception: return np.nan\n",
    "\n",
    "        returned = 0\n",
    "        with_quotes = 0\n",
    "        with_last   = 0\n",
    "\n",
    "        for msg in msgs:\n",
    "            if not msg.hasElement(\"securityData\"): continue\n",
    "            sdata = msg.getElement(\"securityData\")\n",
    "            for i in range(sdata.numValues()):\n",
    "                e = sdata.getValueAsElement(i)\n",
    "                sec = e.getElementAsString(\"security\")\n",
    "                if not e.hasElement(\"fieldData\"): continue\n",
    "                fd = e.getElement(\"fieldData\")\n",
    "                returned += 1\n",
    "\n",
    "                bid = pd.to_numeric(_get(fd, \"BID\"), errors=\"coerce\")\n",
    "                ask = pd.to_numeric(_get(fd, \"ASK\"), errors=\"coerce\")\n",
    "                last= pd.to_numeric(_get(fd, \"LAST_PRICE\"), errors=\"coerce\")\n",
    "\n",
    "                mid = np.nan\n",
    "                if pd.notna(bid) and pd.notna(ask):\n",
    "                    with_quotes += 1\n",
    "                    mid = (float(bid) + float(ask)) / 2.0\n",
    "                elif pd.notna(last):\n",
    "                    with_last += 1\n",
    "                    mid = float(last)\n",
    "\n",
    "                if pd.isna(mid):\n",
    "                    continue  # still nothing usable\n",
    "\n",
    "                Kfd  = _get(fd, \"OPT_STRIKE_PX\")\n",
    "                Efd  = _get(fd, \"OPT_EXPIRE_DT\")\n",
    "                PCfd = _get(fd, \"OPT_PUT_CALL\")\n",
    "                iv1  = _get(fd, \"IVOL_MID\")\n",
    "                iv2  = _get(fd, \"IMPLIED_VOLATILITY\")\n",
    "\n",
    "                meta_row = meta_map.get(sec, {})\n",
    "                K = float(Kfd) if pd.notna(Kfd) else meta_row.get(\"K\", np.nan)\n",
    "                E = (Efd if isinstance(Efd, pd.Timestamp) else\n",
    "                     (pd.to_datetime(Efd) if pd.notna(Efd) else meta_row.get(\"expiry\", np.nan)))\n",
    "                cp = (str(PCfd).upper() if isinstance(PCfd, str) else meta_row.get(\"cp\", None))\n",
    "\n",
    "                rows.append({\n",
    "                    \"security\": sec,\n",
    "                    \"OPT_STRIKE_PX\": K,\n",
    "                    \"OPT_EXPIRE_DT\": E,\n",
    "                    \"OPT_PUT_CALL\": cp,\n",
    "                    \"BID\": float(bid) if pd.notna(bid) else np.nan,\n",
    "                    \"ASK\": float(ask) if pd.notna(ask) else np.nan,\n",
    "                    \"LAST_PRICE\": float(last) if pd.notna(last) else np.nan,\n",
    "                    \"MID\": mid,\n",
    "                    \"IMPLIED_VOLATILITY\": (pd.to_numeric(iv1, errors=\"coerce\")\n",
    "                                           if pd.notna(iv1) else pd.to_numeric(iv2, errors=\"coerce\"))\n",
    "                })\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"[chain] returned: {returned}, with quotes: {with_quotes}, with last-only: {with_last}\")\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "        if df.empty:\n",
    "            if verbose: print(\"[chain] No valid options returned via BDP.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Clean & filter by DTE\n",
    "        df = df.dropna(subset=[\"OPT_STRIKE_PX\",\"OPT_EXPIRE_DT\",\"OPT_PUT_CALL\",\"MID\"]).copy()\n",
    "        df[\"OPT_EXPIRE_DT\"] = pd.to_datetime(df[\"OPT_EXPIRE_DT\"], errors=\"coerce\")\n",
    "        df[\"DTE\"] = (df[\"OPT_EXPIRE_DT\"] - pd.Timestamp(trade_date)).dt.days\n",
    "        df = df[(df[\"DTE\"]>=target_min_dte) & (df[\"DTE\"]<=target_max_dte)]\n",
    "        if df.empty:\n",
    "            if verbose: print(\"[chain] All candidates filtered out by DTE window.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Pair ATM per expiry\n",
    "        df[\"atm_dist\"] = (df[\"OPT_STRIKE_PX\"] - spot_px).abs()\n",
    "        df[\"OPT_PUT_CALL\"] = df[\"OPT_PUT_CALL\"].astype(str).str.upper()\n",
    "        atmC = df[df[\"OPT_PUT_CALL\"]==\"C\"].sort_values([\"atm_dist\",\"DTE\"]).groupby(\"OPT_EXPIRE_DT\").head(1)\n",
    "        atmP = df[df[\"OPT_PUT_CALL\"]==\"P\"].sort_values([\"atm_dist\",\"DTE\"]).groupby(\"OPT_EXPIRE_DT\").head(1)\n",
    "        pair = atmC.merge(atmP, on=\"OPT_EXPIRE_DT\", suffixes=(\"_C\",\"_P\"))\n",
    "        if pair.empty:\n",
    "            if verbose: print(\"[chain] Could not pair ATM call/put on any expiry.\")\n",
    "            return pd.DataFrame()\n",
    "        pair[\"combo_dist\"] = pair[\"atm_dist_C\"] + pair[\"atm_dist_P\"]\n",
    "        best = pair.sort_values([\"combo_dist\",\"DTE_C\"]).head(1)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"[chain] picked expiry {best['OPT_EXPIRE_DT'].iloc[0].date()}, Kâ‰ˆ{best['OPT_STRIKE_PX_C'].iloc[0]}\")\n",
    "\n",
    "        return pd.DataFrame([{\n",
    "            \"expiry\":   best[\"OPT_EXPIRE_DT\"].iloc[0],\n",
    "            \"DTE\":      int(best[\"DTE_C\"].iloc[0]),\n",
    "            \"call_tkr\": best[\"security_C\"].iloc[0],\n",
    "            \"put_tkr\":  best[\"security_P\"].iloc[0],\n",
    "            \"K\":        float(best[\"OPT_STRIKE_PX_C\"].iloc[0]),\n",
    "            \"C_mid\":    float(best[\"MID_C\"].iloc[0]),\n",
    "            \"P_mid\":    float(best[\"MID_P\"].iloc[0]),\n",
    "            \"IV_call\":  float(best[\"IMPLIED_VOLATILITY_C\"].iloc[0]) if pd.notna(best[\"IMPLIED_VOLATILITY_C\"].iloc[0]) else np.nan,\n",
    "            \"IV_put\":   float(best[\"IMPLIED_VOLATILITY_P\"].iloc[0]) if pd.notna(best[\"IMPLIED_VOLATILITY_P\"].iloc[0]) else np.nan\n",
    "        }])\n",
    "    finally:\n",
    "        s.stop()\n",
    "    # ---- helpers ----\n",
    "    def _bbg_base(under):\n",
    "        # \"AAPL US Equity\" -> \"AAPL US\"\n",
    "        parts = under.split()\n",
    "        if len(parts) < 3:\n",
    "            raise ValueError(f\"Unexpected underlying format: {under}\")\n",
    "        return f\"{parts[0]} {parts[1]}\"\n",
    "\n",
    "    def _fridays_between(start_dt, min_dte, max_dte):\n",
    "        fr = []\n",
    "        for d in range(min_dte, max_dte + 1):\n",
    "            dt = start_dt + timedelta(days=d)\n",
    "            if dt.weekday() == 4:  # Friday\n",
    "                fr.append(dt)\n",
    "        return fr\n",
    "\n",
    "    def _third_fridays(start_dt, count=6):\n",
    "        # next N standard monthly expiries (third Friday)\n",
    "        exps, dt = [], start_dt\n",
    "        while len(exps) < count:\n",
    "            # move to first day next month\n",
    "            y, m = dt.year + (dt.month // 12), (dt.month % 12) + 1\n",
    "            first_next = pd.Timestamp(year=y, month=m, day=1)\n",
    "            # third Friday of that month\n",
    "            wd = first_next.weekday()\n",
    "            # Friday index in that month: find first Friday then add 14 days\n",
    "            first_friday = first_next + timedelta(days=(4 - wd) % 7)\n",
    "            third_friday = first_friday + timedelta(days=14)\n",
    "            exps.append(third_friday)\n",
    "            dt = third_friday\n",
    "        return exps\n",
    "\n",
    "    def _strike_increment(S):\n",
    "        # heuristic for US equity option grids\n",
    "        if S < 25:   return 0.5\n",
    "        if S < 200:  return 1.0\n",
    "        if S < 500:  return 2.5\n",
    "        if S < 1000: return 5.0\n",
    "        return 10.0\n",
    "\n",
    "    def _atm_ladder(S, steps=4):\n",
    "        inc = _strike_increment(S)\n",
    "        k0  = round(S / inc) * inc\n",
    "        ks  = [k0 + i*inc for i in range(-steps, steps+1)]\n",
    "        # also add a coarser grid around spot to catch odd OCC ladders\n",
    "        coarse = [k0 + i*(5*inc) for i in range(-2, 3)]\n",
    "        ks = sorted(set([round(k, 2) for k in ks + coarse]))\n",
    "        return ks\n",
    "\n",
    "    def _format_bbg_opt(base, exp_dt, cp, strike):\n",
    "        mmddyy = pd.Timestamp(exp_dt).strftime(\"%m/%d/%y\")\n",
    "        if abs(strike - round(strike)) < 1e-6:\n",
    "            strike_txt = str(int(round(strike)))\n",
    "        else:\n",
    "            strike_txt = f\"{strike:.2f}\".rstrip(\"0\").rstrip(\".\")\n",
    "        return f\"{base} {mmddyy} {cp}{strike_txt} Equity\"\n",
    "\n",
    "    # ---- assemble candidates ----\n",
    "    base = _bbg_base(underlying_bbg)\n",
    "    trade_dt = pd.Timestamp(trade_date)\n",
    "\n",
    "    expiry_fridays = _fridays_between(trade_dt, target_min_dte, target_max_dte)\n",
    "    expiry_monthlies = _third_fridays(trade_dt, count=6)\n",
    "    expiries = sorted(set(expiry_fridays + expiry_monthlies))[:24]  # cap to 24 expiries\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"[chain] expiries candidates: {len(expiries)} (min_dte={target_min_dte}, max_dte={target_max_dte})\")\n",
    "\n",
    "    if not expiries:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    strikes = _atm_ladder(spot_px, steps=5)  # 5 steps each side + coarse grid\n",
    "    if verbose:\n",
    "        print(f\"[chain] strike candidates around spot {spot_px:.2f}: {len(strikes)}\")\n",
    "\n",
    "    # Build bulk list\n",
    "    sec_list, meta = [], []\n",
    "    for exp in expiries:\n",
    "        for cp in (\"C\", \"P\"):\n",
    "            for K in strikes:\n",
    "                sec = _format_bbg_opt(base, exp, cp, K)\n",
    "                sec_list.append(sec)\n",
    "                meta.append({\"sec\": sec, \"cp\": cp, \"K\": float(K), \"expiry\": pd.Timestamp(exp)})\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"[chain] requesting {len(sec_list)} option securities via BDP\")\n",
    "\n",
    "    # ---- BDP request ----\n",
    "    s, ref = _start_bbg_session()\n",
    "    try:\n",
    "        fields = [\n",
    "            \"PX_BID\",\"PX_ASK\",\n",
    "            \"OPT_STRIKE_PX\",\"OPT_EXPIRE_DT\",\"OPT_PUT_CALL\",\n",
    "            \"IVOL_MID\",\"IMPLIED_VOLATILITY\"\n",
    "        ]\n",
    "        bdp = ref.createRequest(\"ReferenceDataRequest\")\n",
    "        se = bdp.getElement(\"securities\"); [se.appendValue(sec) for sec in sec_list]\n",
    "        fe = bdp.getElement(\"fields\");     [fe.appendValue(f)   for f   in fields]\n",
    "        msgs = _send_req(s, bdp)\n",
    "\n",
    "        rows = []\n",
    "        meta_map = {m[\"sec\"]: m for m in meta}\n",
    "\n",
    "        def _get(fd, name):\n",
    "            if not fd.hasElement(name): return np.nan\n",
    "            sub = fd.getElement(name)\n",
    "            for meth in (\"getValueAsFloat64\",\"getValueAsInt64\",\"getValueAsInteger\"):\n",
    "                try: return getattr(sub, meth)()\n",
    "                except Exception: pass\n",
    "            for meth in (\"getValueAsDatetime\",\"getValueAsString\"):\n",
    "                try:\n",
    "                    val = getattr(sub, meth)()\n",
    "                    if isinstance(val, blpapi.Datetime):\n",
    "                        return pd.to_datetime(val.strftime(\"%Y-%m-%d\"))\n",
    "                    return val\n",
    "                except Exception: pass\n",
    "            try: return sub.getValue()\n",
    "            except Exception: return np.nan\n",
    "\n",
    "        returned = 0\n",
    "        with_quotes = 0\n",
    "        for msg in msgs:\n",
    "            if not msg.hasElement(\"securityData\"): continue\n",
    "            sdata = msg.getElement(\"securityData\")\n",
    "            for i in range(sdata.numValues()):\n",
    "                e = sdata.getValueAsElement(i)\n",
    "                sec = e.getElementAsString(\"security\")\n",
    "                if not e.hasElement(\"fieldData\"): continue\n",
    "                fd = e.getElement(\"fieldData\")\n",
    "                returned += 1\n",
    "\n",
    "                bid = pd.to_numeric(_get(fd, \"PX_BID\"), errors=\"coerce\")\n",
    "                ask = pd.to_numeric(_get(fd, \"PX_ASK\"), errors=\"coerce\")\n",
    "                if pd.isna(bid) and pd.isna(ask):\n",
    "                    continue  # skip dead securities\n",
    "                with_quotes += 1\n",
    "\n",
    "                Kfd  = _get(fd, \"OPT_STRIKE_PX\")\n",
    "                Efd  = _get(fd, \"OPT_EXPIRE_DT\")\n",
    "                PCfd = _get(fd, \"OPT_PUT_CALL\")\n",
    "                iv1  = _get(fd, \"IVOL_MID\")\n",
    "                iv2  = _get(fd, \"IMPLIED_VOLATILITY\")\n",
    "\n",
    "                meta_row = meta_map.get(sec, {})\n",
    "                K = float(Kfd) if pd.notna(Kfd) else meta_row.get(\"K\", np.nan)\n",
    "                E = (Efd if isinstance(Efd, pd.Timestamp) else\n",
    "                     (pd.to_datetime(Efd) if pd.notna(Efd) else meta_row.get(\"expiry\", np.nan)))\n",
    "                cp = (str(PCfd).upper() if isinstance(PCfd, str) else meta_row.get(\"cp\", None))\n",
    "\n",
    "                rows.append({\n",
    "                    \"security\": sec,\n",
    "                    \"OPT_STRIKE_PX\": K,\n",
    "                    \"OPT_EXPIRE_DT\": E,\n",
    "                    \"OPT_PUT_CALL\": cp,\n",
    "                    \"PX_BID\": float(bid) if pd.notna(bid) else np.nan,\n",
    "                    \"PX_ASK\": float(ask) if pd.notna(ask) else np.nan,\n",
    "                    \"MID\": np.nan if (pd.isna(bid) or pd.isna(ask)) else (float(bid)+float(ask))/2.0,\n",
    "                    \"IMPLIED_VOLATILITY\": (pd.to_numeric(iv1, errors=\"coerce\")\n",
    "                                           if pd.notna(iv1) else pd.to_numeric(iv2, errors=\"coerce\"))\n",
    "                })\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"[chain] returned: {returned}, with quotes: {with_quotes}\")\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "        if df.empty:\n",
    "            if verbose: print(\"[chain] No valid options returned via BDP.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Clean & filter by DTE\n",
    "        df = df.dropna(subset=[\"OPT_STRIKE_PX\",\"OPT_EXPIRE_DT\",\"OPT_PUT_CALL\",\"MID\"]).copy()\n",
    "        df[\"OPT_EXPIRE_DT\"] = pd.to_datetime(df[\"OPT_EXPIRE_DT\"], errors=\"coerce\")\n",
    "        trade_dt = pd.Timestamp(trade_date)\n",
    "        df[\"DTE\"] = (df[\"OPT_EXPIRE_DT\"] - trade_dt).dt.days\n",
    "        df = df[(df[\"DTE\"]>=target_min_dte) & (df[\"DTE\"]<=target_max_dte)]\n",
    "        if df.empty:\n",
    "            if verbose: print(\"[chain] All candidates filtered out by DTE window.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Pair ATM per expiry\n",
    "        df[\"atm_dist\"] = (df[\"OPT_STRIKE_PX\"] - spot_px).abs()\n",
    "        df[\"OPT_PUT_CALL\"] = df[\"OPT_PUT_CALL\"].astype(str).str.upper()\n",
    "        atmC = df[df[\"OPT_PUT_CALL\"]==\"C\"].sort_values([\"atm_dist\",\"DTE\"]).groupby(\"OPT_EXPIRE_DT\").head(1)\n",
    "        atmP = df[df[\"OPT_PUT_CALL\"]==\"P\"].sort_values([\"atm_dist\",\"DTE\"]).groupby(\"OPT_EXPIRE_DT\").head(1)\n",
    "        pair = atmC.merge(atmP, on=\"OPT_EXPIRE_DT\", suffixes=(\"_C\",\"_P\"))\n",
    "        if pair.empty:\n",
    "            if verbose: print(\"[chain] Could not pair ATM call/put on any expiry.\")\n",
    "            return pd.DataFrame()\n",
    "        pair[\"combo_dist\"] = pair[\"atm_dist_C\"] + pair[\"atm_dist_P\"]\n",
    "        best = pair.sort_values([\"combo_dist\",\"DTE_C\"]).head(1)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"[chain] picked expiry {best['OPT_EXPIRE_DT'].iloc[0].date()}, Kâ‰ˆ{best['OPT_STRIKE_PX_C'].iloc[0]}\")\n",
    "\n",
    "        return pd.DataFrame([{\n",
    "            \"expiry\":   best[\"OPT_EXPIRE_DT\"].iloc[0],\n",
    "            \"DTE\":      int(best[\"DTE_C\"].iloc[0]),\n",
    "            \"call_tkr\": best[\"security_C\"].iloc[0],\n",
    "            \"put_tkr\":  best[\"security_P\"].iloc[0],\n",
    "            \"K\":        float(best[\"OPT_STRIKE_PX_C\"].iloc[0]),\n",
    "            \"C_mid\":    float(best[\"MID_C\"].iloc[0]),\n",
    "            \"P_mid\":    float(best[\"MID_P\"].iloc[0]),\n",
    "            \"IV_call\":  float(best[\"IMPLIED_VOLATILITY_C\"].iloc[0]) if pd.notna(best[\"IMPLIED_VOLATILITY_C\"].iloc[0]) else np.nan,\n",
    "            \"IV_put\":   float(best[\"IMPLIED_VOLATILITY_P\"].iloc[0]) if pd.notna(best[\"IMPLIED_VOLATILITY_P\"].iloc[0]) else np.nan\n",
    "        }])\n",
    "    finally:\n",
    "        s.stop()\n",
    "\n",
    "# -------------------- Quant helpers --------------------\n",
    "def black_scholes_price(S, K, T, r, sigma, cp):\n",
    "    d1 = (np.log(S/K) + (r + 0.5*sigma*sigma)*T)/(sigma*np.sqrt(T))\n",
    "    d2 = d1 - sigma*np.sqrt(T)\n",
    "    return (S*norm.cdf(d1) - K*np.exp(-r*T)*norm.cdf(d2)) if cp.upper()==\"C\" else (K*np.exp(-r*T)*norm.cdf(-d2) - S*norm.cdf(-d1))\n",
    "\n",
    "def realized_vol_from_close(close):\n",
    "    ret = np.log(close/close.shift(1)).dropna()\n",
    "    return ret.rolling(21).std()*np.sqrt(252)\n",
    "\n",
    "# -------------------- Backtest --------------------\n",
    "def backtest_parity(\n",
    "    underlying=\"AAPL US Equity\",\n",
    "    start=\"20240101\",\n",
    "    end  =\"20250918\",\n",
    "    min_dte=25, max_dte=45,\n",
    "    gap_threshold=0.10,\n",
    "    max_hold_days=60,\n",
    "    riskfree_ticker=\"USGG3M Index\",\n",
    "    step_days=1,\n",
    "    progress_every=10\n",
    "):\n",
    "    px = get_bdh_equity(underlying, start, end, fields=(\"PX_LAST\",))\n",
    "    rf = get_riskfree_series(start, end, ticker=riskfree_ticker)\n",
    "    df = px.join(rf, how=\"left\").ffill()\n",
    "    df[\"rv_21\"] = realized_vol_from_close(df[\"PX_LAST\"])\n",
    "\n",
    "    trades, equity_curve = [], []\n",
    "    open_pos = None\n",
    "    dates = df.index.to_list()\n",
    "\n",
    "    for idx, dt in enumerate(dates):\n",
    "        if step_days > 1 and idx % step_days != 0:\n",
    "            equity_curve.append({\"date\": dt, \"equity\": 0.0 if not open_pos else open_pos[\"equity_mark\"]})\n",
    "            continue\n",
    "\n",
    "        S = float(df.loc[dt, \"PX_LAST\"])\n",
    "        rf_day = float(df.loc[dt, \"rf_daily\"]) if \"rf_daily\" in df.columns and pd.notna(df.loc[dt, \"rf_daily\"]) else 0.0\n",
    "\n",
    "        if open_pos:\n",
    "            open_pos[\"days_held\"] += step_days\n",
    "            open_pos[\"cash\"] *= (1.0 + rf_day) ** step_days\n",
    "            equity_curve.append({\"date\": dt, \"equity\": open_pos[\"equity_mark\"]})\n",
    "        else:\n",
    "            equity_curve.append({\"date\": dt, \"equity\": 0.0})\n",
    "\n",
    "        if open_pos:\n",
    "            if dt >= open_pos[\"expiry\"] or open_pos[\"days_held\"] >= max_hold_days:\n",
    "                pnl = open_pos[\"gap_signed\"]\n",
    "                trades.append({**open_pos, \"exit_date\": dt, \"pnl\": pnl})\n",
    "                open_pos = None\n",
    "            continue\n",
    "\n",
    "        chain = get_chain_for_day(underlying, S, dt, min_dte, max_dte, max_points=600, verbose=True)\n",
    "        if chain.empty:\n",
    "            if progress_every and idx % progress_every == 0:\n",
    "                print(f\"[{dt.date()}] No options found in DTE window ({min_dte}-{max_dte}).\")\n",
    "            continue\n",
    "\n",
    "        K    = chain[\"K\"].iloc[0]\n",
    "        Cmid = chain[\"C_mid\"].iloc[0]\n",
    "        Pmid = chain[\"P_mid\"].iloc[0]\n",
    "        expiry = chain[\"expiry\"].iloc[0]\n",
    "        dte   = int(chain[\"DTE\"].iloc[0])\n",
    "        T     = dte/365.0\n",
    "\n",
    "        r_ann = (df.loc[dt, \"rf_daily\"]*365.0) if \"rf_daily\" in df.columns and pd.notna(df.loc[dt, \"rf_daily\"]) else 0.0\n",
    "        dfac  = np.exp(-r_ann*T)\n",
    "        gap   = (Cmid - Pmid) - (S - K*dfac)\n",
    "\n",
    "        if abs(gap) < gap_threshold:\n",
    "            if progress_every and idx % progress_every == 0:\n",
    "                print(f\"[{dt.date()}] Gap {gap:.3f} < thr {gap_threshold}\")\n",
    "            continue\n",
    "\n",
    "        direction = \"short_call_long_put_shortS_longB\" if gap > 0 else \"long_call_short_put_longS_shortB\"\n",
    "        open_pos = {\n",
    "            \"entry_date\": dt, \"expiry\": expiry, \"days_held\": 0,\n",
    "            \"underlying\": underlying,\n",
    "            \"S0\": S, \"K\": K, \"C_mid0\": Cmid, \"P_mid0\": Pmid,\n",
    "            \"r_ann\": r_ann, \"T\": T, \"dte\": dte,\n",
    "            \"gap\": float(gap), \"gap_signed\": float(np.sign(gap)*abs(gap)),\n",
    "            \"direction\": direction,\n",
    "            \"cash\": K*dfac if gap>0 else -K*dfac,\n",
    "            \"equity_mark\": float(np.sign(gap)*abs(gap))\n",
    "        }\n",
    "\n",
    "        if progress_every and idx % progress_every == 0:\n",
    "            print(f\"[{dt.date()}] ENTER {direction} | DTE={dte} K={K:.2f} S={S:.2f} gap={gap:.3f}\")\n",
    "\n",
    "    eq = pd.DataFrame(equity_curve).set_index(\"date\")\n",
    "    tr = pd.DataFrame(trades)\n",
    "\n",
    "    if not tr.empty:\n",
    "        total_pnl = tr[\"pnl\"].sum()\n",
    "        hitrate   = (tr[\"pnl\"]>0).mean()\n",
    "        avg_hold  = tr[\"days_held\"].mean()\n",
    "    else:\n",
    "        total_pnl = 0.0; hitrate = np.nan; avg_hold = np.nan\n",
    "\n",
    "    return {\n",
    "        \"underlying_history\": df,\n",
    "        \"equity_curve\": eq,\n",
    "        \"trades\": tr,\n",
    "        \"summary\": {\n",
    "            \"total_pnl_units\": float(total_pnl),\n",
    "            \"num_trades\": int(len(tr)),\n",
    "            \"hit_ratio\": float(hitrate) if pd.notna(hitrate) else None,\n",
    "            \"avg_hold_days\": float(avg_hold) if pd.notna(avg_hold) else None\n",
    "        }\n",
    "    }\n",
    "\n",
    "# -------------------- Plot helper --------------------\n",
    "def plot_backtest(res, title=\"Parity Arbitrage Backtest\", outfile=None):\n",
    "    if not isinstance(res, dict) or \"summary\" not in res or res[\"summary\"].get(\"num_trades\", 0) == 0:\n",
    "        print(\"No trades â€” skipping plot.\")\n",
    "        return\n",
    "\n",
    "    uh = res[\"underlying_history\"].copy()\n",
    "    tr = res[\"trades\"].copy().set_index(\"exit_date\").sort_index() if not res[\"trades\"].empty else pd.DataFrame()\n",
    "    daily = pd.Series(0.0, index=uh.index)\n",
    "    if not tr.empty:\n",
    "        for dt, row in tr.iterrows():\n",
    "            if dt in daily.index:\n",
    "                daily.loc[dt] += float(row[\"pnl\"])\n",
    "    cum_pnl = daily.cumsum()\n",
    "    if outfile is None:\n",
    "        outfile = Path(f\"./backtest_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\")\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(cum_pnl.index, cum_pnl.values, linewidth=2)\n",
    "    plt.title(title); plt.xlabel(\"Date\"); plt.ylabel(\"Cumulative Realized PnL (units)\")\n",
    "    plt.grid(True, linewidth=0.5, alpha=0.6); plt.tight_layout()\n",
    "    plt.savefig(outfile, dpi=200); plt.close()\n",
    "    print(\"Saved chart to:\", outfile)\n",
    "\n",
    "# -------------------- Example run --------------------\n",
    "underlying = \"AAPL US Equity\"        # try other US names once AAPL works\n",
    "start      = \"20240701\"\n",
    "end        = \"20240815\"\n",
    "min_dte, max_dte = 10, 60\n",
    "gap_threshold    = 0.05\n",
    "\n",
    "res = backtest_parity(\n",
    "    underlying=underlying,\n",
    "    start=start,\n",
    "    end=end,\n",
    "    min_dte=min_dte,\n",
    "    max_dte=max_dte,\n",
    "    gap_threshold=gap_threshold,\n",
    "    riskfree_ticker=\"USGG3M Index\",\n",
    "    step_days=2,\n",
    "    progress_every=5\n",
    ")\n",
    "print(\"Summary:\", res[\"summary\"])\n",
    "outfile = f\"{underlying.replace(' ','_')}_parity_backtest.png\"\n",
    "plot_backtest(res, title=f\"{underlying} Parity Arbitrage Backtest\", outfile=outfile)\n",
    "print(f\"Chart path: {outfile}\")\n",
    "# ==============================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7e34ad-67a9-4c85-b2ef-c3ef9e7926b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bbg310)",
   "language": "python",
   "name": "bbg310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
